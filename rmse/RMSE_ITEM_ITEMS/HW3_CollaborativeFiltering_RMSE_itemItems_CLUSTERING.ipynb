{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "import time\n",
    "import nltk\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import stem\n",
    "import sklearn.metrics\n",
    "from random import randint\n",
    "from numpy.linalg import norm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "with open('../new_userDict.json', 'r') as fp:\n",
    "    \n",
    "    new_userDict = json.load(fp)\n",
    "    \n",
    "with open('../new_isbnDict.json', 'r') as fp:\n",
    "    \n",
    "    new_isbnDict = json.load(fp)\n",
    "    \n",
    "with open('../dict_row.json', 'r') as fp:\n",
    "    \n",
    "    dict_row = json.load(fp)\n",
    "    \n",
    "with open('../dict_col.json', 'r') as fp:\n",
    "    \n",
    "    dict_col = json.load(fp)\n",
    "    \n",
    "        \n",
    "print(\"Ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "with open('../clustering/CLUSTERS_ITEMS.json', 'r') as fp:\n",
    "    \n",
    "    CLUSTERS_ITEMS = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('../clustering/CLUSTERS_USERS.json', 'r') as fp:\n",
    "    \n",
    "    CLUSTERS_USERS = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('../clustering/file/clusters_dict_row.json', 'r') as fp:\n",
    "    \n",
    "    clusters_dict_row = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('../clustering/file/clusters_dict_col.json', 'r') as fp:\n",
    "    \n",
    "    clusters_dict_col = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('../clustering/cluster_book_dict.json', 'r') as fp:\n",
    "    \n",
    "    cluster_book_dict = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('../clustering/cluster_users_dict.json', 'r') as fp:\n",
    "    \n",
    "    cluster_users_dict = json.load(fp)\n",
    "    \n",
    "print(\"Ok\") \n",
    "\n",
    "\n",
    "\n",
    "with open('../clustering/index_book_user_clusters/index_user_cluster.json', 'r') as fp:\n",
    "    \n",
    "    index_user_cluster = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('../clustering/index_book_user_clusters/index_book_cluster.json', 'r') as fp:\n",
    "    \n",
    "    index_book_cluster = json.load(fp)\n",
    "    \n",
    "print(\"Ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def booksRatedUser(new_isbnDict, new_userDict, user_number, score):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    input:  new_userDict (Dict), user_number (int), score (int)\n",
    "    \n",
    "    action: select all books rated by my user\n",
    "    \n",
    "    output: books_rated (list)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    books_rated = []\n",
    "    \n",
    "    for book in new_userDict[str(user_number)]:\n",
    "        \n",
    "        if int(new_userDict[str(user_number)][book]) > score:\n",
    "            \n",
    "            try:\n",
    "                new_isbnDict[book]\n",
    "                books_rated.append(book)\n",
    "                \n",
    "            except:\n",
    "                \n",
    "                continue\n",
    "            \n",
    "    return list(set(books_rated))\n",
    "\n",
    "\n",
    "def SimilarityBooks(utility_DataFrame, book_number, books_similar):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    input: utility_DataFrame (DataFrame), book_number (int), books_similar (List)\n",
    "    \n",
    "    action: compute cosine similarity between book_number and all the books in books_similar\n",
    "    \n",
    "    output: new_similarity (List of tuples)\n",
    "    \n",
    "    '''\n",
    "\n",
    "    x = utility_DataFrame[str(book_number)]\n",
    "    x_length = norm(x)\n",
    "    \n",
    "    y = utility_DataFrame[books_similar]\n",
    "    y_length = norm(utility_DataFrame[books_similar],axis=0)\n",
    "\n",
    "    \n",
    "    num = (y.T.values*x.values).sum(axis=1)\n",
    "    den = x_length*y_length\n",
    "\n",
    "    similarity = num/den\n",
    "    similarity = np.nan_to_num(similarity)\n",
    "    \n",
    "    d = list(zip(list(books_similar),similarity))\n",
    "    new_similarity = sorted(d, key=lambda tup: tup[1], reverse=True)\n",
    "    \n",
    "    return new_similarity\n",
    "\n",
    "\n",
    "def itemItemsRecommendation(new_similarity, user_number, book_number, k, new_userDict):\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    input:  new_similarity(List of tuples), new_isbnDict(Dict), k(int)\n",
    "    \n",
    "    action: compute mean similarity of the first k items\n",
    "    \n",
    "    output: recommendation (float)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    if len(new_similarity) < k:\n",
    "        \n",
    "        recommendation = np.mean([u[1] for u in new_similarity])\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        recommendation = np.mean([u[1] for u in new_similarity[:k]])\n",
    "        \n",
    "    \n",
    "    return recommendation\n",
    "\n",
    "\n",
    "def itemItemsScore(new_userDict, new_similarity, k, user_number):\n",
    "    \n",
    "    score = [int(new_userDict[str(user_number)][u[0]]) for u in new_similarity[:k]]\n",
    "    \n",
    "    if score == []:\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    return np.mean(score)\n",
    "\n",
    "\n",
    "def CollaborativeFilteringItemItemsRMSE(utility_DataFrame, new_userDict, new_isbnDict, user_number, score_min, book_number, k):\n",
    "    \n",
    "    books_rated_user = booksRatedUser(new_isbnDict, new_userDict, user_number,score_min)\n",
    "    \n",
    "    if books_rated_user == []:\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    new_similarity = SimilarityBooks(utility_DataFrame, book_number, books_rated_user)\n",
    "    \n",
    "    if new_similarity == []:\n",
    "\n",
    "        return None\n",
    "    \n",
    "    score = itemItemsScore(new_userDict, new_similarity[1:], k, user_number)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert(user_number,book_number, index_user_cluster, index_book_cluster):\n",
    "    \n",
    "    user_cluster = index_user_cluster[user_number]\n",
    "    book_cluster = index_book_cluster[book_number]\n",
    "    \n",
    "    return user_cluster, book_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createSampleDict(new_isbnDict, new_userDict, t1, t2):\n",
    "    \n",
    "\n",
    "    small_isbnDict = {}\n",
    "\n",
    "    for book in new_isbnDict:\n",
    "\n",
    "        temp = new_isbnDict[book]\n",
    "        i = 0\n",
    "\n",
    "        for t in temp.values():\n",
    "            if t != \"0\":\n",
    "                i = i+1\n",
    "\n",
    "        if i >t1:\n",
    "\n",
    "            small_isbnDict[book] = new_isbnDict[book]   \n",
    "\n",
    "    small_userDict = {}\n",
    "\n",
    "    for user in new_userDict:\n",
    "\n",
    "        temp = new_userDict[user]\n",
    "        i = 0\n",
    "\n",
    "        for t in temp.values():\n",
    "            if t != \"0\":\n",
    "                i = i+1\n",
    "\n",
    "        if i >t2:\n",
    "\n",
    "            small_userDict[user] = new_userDict[user]\n",
    "            \n",
    "            \n",
    "    return small_isbnDict, small_userDict\n",
    "\n",
    "\n",
    "def computeMatrices(train_userDict,train_isbnDict,small_userDict,small_isbnDict, dict_row, dict_col):\n",
    "\n",
    "    n = len(small_isbnDict)\n",
    "    m = len(small_userDict)\n",
    "    \n",
    "    index = sorted(small_userDict.keys())\n",
    "    columns = sorted(small_isbnDict.keys())\n",
    "\n",
    "    dict_row = {k:v for v,k in enumerate(index)}\n",
    "    dict_col = {k:v for v,k in enumerate(columns)}\n",
    "\n",
    "    u = np.zeros((m,n)) \n",
    "    R = np.zeros((m,n))\n",
    "    for user in train_userDict:\n",
    "        for isbn in train_userDict[user]:\n",
    "            try:\n",
    "                u[dict_row[user]][dict_col[isbn]] = train_userDict[user][isbn]\n",
    "                R[dict_row[user]][dict_col[isbn]] = 1\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    for isbn in train_isbnDict:\n",
    "        for user in train_isbnDict[isbn]:\n",
    "            try:\n",
    "                u[dict_row[user]][dict_col[isbn]] = train_isbnDict[isbn][user]\n",
    "                R[dict_row[user]][dict_col[isbn]] = 1\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    small_utility_DataFrame = pd.DataFrame(u, index = index, columns = columns)\n",
    "    R = pd.DataFrame(R, index = index, columns = columns)\n",
    "\n",
    "    return u, R, small_utility_DataFrame\n",
    "\n",
    "\n",
    "def selectSample(i,b,list_user,small_userDict, small_isbnDict):\n",
    "\n",
    "    test_index = [k for k in range((i*b),(i+1)*b)]\n",
    "    train_index = [k for k in range(len(list_user)) if k not in test_index]\n",
    "\n",
    "    train = list_user[train_index]\n",
    "    test  = list_user[test_index]\n",
    "\n",
    "    train_userDict = {}\n",
    "    train_isbnDict = {isbn:{} for isbn in small_isbnDict}\n",
    "\n",
    "    for user in train:\n",
    "\n",
    "        train_userDict[user] = small_userDict[user]\n",
    "\n",
    "    for isbn in small_isbnDict:\n",
    "        for user in small_isbnDict[isbn]:\n",
    "\n",
    "            try:\n",
    "                train_userDict[user]\n",
    "                train_isbnDict[isbn][user] = small_isbnDict[isbn][user]\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "                \n",
    "    test_userDict = {}\n",
    "    test_isbnDict = {isbn:{} for isbn in small_isbnDict}\n",
    "\n",
    "    for user in test:\n",
    "\n",
    "        test_userDict[user] = small_userDict[user]\n",
    "\n",
    "    for isbn in small_isbnDict:\n",
    "        for user in small_isbnDict[isbn]:\n",
    "\n",
    "            try:\n",
    "                test_userDict[user]\n",
    "                test_isbnDict[isbn][user] = small_isbnDict[isbn][user]\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    return train_userDict, train_isbnDict, test_userDict, test_isbnDict, test\n",
    "\n",
    "\n",
    "#indices = [i for i in range(len(list_user))]\n",
    "#indices = np.array(indices)\n",
    "#k = 5\n",
    "#b = len(small_userDict)//k\n",
    "\n",
    "\n",
    "def selectSampleRandom(indices,b,list_user,small_userDict, small_isbnDict):\n",
    "    \n",
    "    test_index = np.random.choice(indices, size = b, replace=False)\n",
    "    \n",
    "    indices = np.delete(indices,test_index)\n",
    "    \n",
    "    train_index = [k for k in range(len(list_user)) if k not in test_index]\n",
    "    \n",
    "\n",
    "    train = list_user[train_index]\n",
    "    test  = list_user[test_index]\n",
    "\n",
    "    train_userDict = {}\n",
    "    train_isbnDict = {isbn:{} for isbn in small_isbnDict}\n",
    "\n",
    "    for user in train:\n",
    "\n",
    "        train_userDict[user] = small_userDict[user]\n",
    "\n",
    "    for isbn in small_isbnDict:\n",
    "        for user in small_isbnDict[isbn]:\n",
    "\n",
    "            try:\n",
    "                train_userDict[user]\n",
    "                train_isbnDict[isbn][user] = small_isbnDict[isbn][user]\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    return train_userDict, train_isbnDict, test_userDict, test_isbnDict, test, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mainItemItemsRMSE_clustering(utility_DataFrame,utility_DataFrame_clusters,R_clusters, new_userDict, new_isbnDict,\n",
    "                                 index_user_cluster, index_book_cluster, score_min=0, k=3, zeros= \"n\"):\n",
    "    \n",
    "\n",
    "    rmse_dict = {j:{} for j in new_userDict.keys()}\n",
    "\n",
    "    for user in new_userDict:\n",
    "\n",
    "        for book in new_userDict[user]:\n",
    "\n",
    "            if new_userDict[user][book] != \"0\":\n",
    "                try:\n",
    "                    new_isbnDict[book]\n",
    "                    rmse_dict[user][book] = new_userDict[user][book]\n",
    "                except:\n",
    "                    continue\n",
    "                    \n",
    "            if new_userDict[user][book] == \"0\" and zeros != \"n\":  #if this is true score_min = -1\n",
    "                try:\n",
    "                    new_isbnDict[book]\n",
    "                    rmse_dict[user][book] = \"1\"\n",
    "                except:\n",
    "                    continue\n",
    "                    \n",
    "    d = rmse_dict.keys()\n",
    "    v = []\n",
    "\n",
    "    for key in d:\n",
    "\n",
    "        if rmse_dict[key] == {}:\n",
    "\n",
    "            v.append(key)\n",
    "\n",
    "    for i in v:\n",
    "\n",
    "        del rmse_dict[i]\n",
    "\n",
    "    rmse_vector_itemItems = []\n",
    "    \n",
    "    i = 0\n",
    "    for user in rmse_dict:\n",
    "        \n",
    "        i = i+1\n",
    "        if i%1000 == 0:\n",
    "            \n",
    "            print(\"Pause\")\n",
    "            time.sleep(30)\n",
    "\n",
    "        for isbn in rmse_dict[user]:\n",
    "            \n",
    "            prediction_score = None\n",
    "            user_number = user\n",
    "            book_number = isbn\n",
    "            \n",
    "            \n",
    "            try:\n",
    "                \n",
    "                prediction_score = CollaborativeFilteringItemItemsRMSE(utility_DataFrame, new_userDict, new_isbnDict, \n",
    "                                                                   user_number, score_min, book_number, k)\n",
    "                true_score = utility_DataFrame[book_number][user_number]\n",
    "                #print(true_score,prediction_score,\"w\")\n",
    "            \n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            if prediction_score == None:\n",
    "                \n",
    "                user_cluster, book_cluster = convert(user_number,book_number, index_user_cluster, index_book_cluster)\n",
    "                \n",
    "                if R_clusters[book_cluster][user_cluster] == 1:\n",
    "                \n",
    "                    prediction_score = utility_DataFrame_clusters[book_cluster][user_cluster]\n",
    "                    true_score = utility_DataFrame[book_number][user_number]\n",
    "\n",
    "                    #print(true_score,prediction_score)\n",
    "                    \n",
    "            if prediction_score != None:\n",
    "\n",
    "                rmse_vector_itemItems.append(tuple([user_number, book_number, prediction_score, true_score]))\n",
    "\n",
    "\n",
    "    rmse = np.sqrt((np.array([u[2]-u[3] for u in rmse_vector_itemItems])**2).sum()/len(rmse_vector_itemItems))\n",
    "    \n",
    "    return rmse, rmse_vector_itemItems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with this approach I use the clusterings only when I don't have informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small_isbnDict, small_userDict = createSampleDict(new_isbnDict, new_userDict, 20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u_clusters, R_clusters, utility_DataFrame_clusters = computeMatrices(CLUSTERS_USERS,CLUSTERS_ITEMS,\n",
    "                                                                           CLUSTERS_USERS,CLUSTERS_ITEMS,\n",
    "                                                                            clusters_dict_row,clusters_dict_col)\n",
    "\n",
    "u, R, utility_DataFrame = computeMatrices(small_userDict,small_isbnDict,new_userDict,new_isbnDict,dict_row,dict_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rmse_test, rmse_vector_itemItems = mainItemItemsRMSE_clustering(utility_DataFrame,utility_DataFrame_clusters,R_clusters,\n",
    "                                                                small_userDict,small_isbnDict,\n",
    "                                                                index_user_cluster,index_book_cluster,\n",
    "                                                                score_min=0,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('190885', '1558743669', 8.0, 9.0),\n",
       " ('190885', '067088300X', 8.0, 6.0),\n",
       " ('190885', '1558531025', 8.3333333333333339, 7.0),\n",
       " ('190885', '0877733759', 7.0, 9.0),\n",
       " ('190885', '1558743316', 8.0, 8.0),\n",
       " ('190885', '0971880107', 8.0, 5.0),\n",
       " ('190885', '0804105820', 8.0, 8.0),\n",
       " ('225659', '0749395990', 8.0, 7.0),\n",
       " ('225659', '2070360024', 7.5, 8.0),\n",
       " ('225659', '0312305060', 7.5, 8.0),\n",
       " ('233711', '1558743669', 8.0, 7.0),\n",
       " ('233711', '0440211727', 7.666666666666667, 8.0),\n",
       " ('233711', '0385484518', 8.0, 9.0),\n",
       " ('233711', '0425144429', 7.666666666666667, 8.0),\n",
       " ('233711', '0446679593', 7.666666666666667, 10.0),\n",
       " ('233711', '0385335482', 8.0, 9.0),\n",
       " ('233711', '0316899984', 7.333333333333333, 5.0),\n",
       " ('233711', '0345384466', 9.0, 5.0),\n",
       " ('233711', '0446606189', 8.0, 7.0),\n",
       " ('233711', '0345439104', 7.333333333333333, 8.0),\n",
       " ('233711', '0425163385', 8.0, 7.0),\n",
       " ('233711', '0060096195', 8.6666666666666661, 9.0),\n",
       " ('233711', '0812570944', 7.0, 8.0),\n",
       " ('233711', '0452284295', 9.3333333333333339, 8.0),\n",
       " ('233711', '0767900383', 8.6666666666666661, 7.0),\n",
       " ('233711', '0743225082', 8.3333333333333339, 8.0),\n",
       " ('233711', '0671021001', 6.666666666666667, 7.0),\n",
       " ('233711', '0440220602', 7.666666666666667, 9.0),\n",
       " ('233711', '038548951X', 6.333333333333333, 10.0),\n",
       " ('233711', '0316284955', 7.666666666666667, 7.0),\n",
       " ('233711', '044021145X', 8.0, 7.0),\n",
       " ('233711', '0553287737', 7.666666666666667, 7.0),\n",
       " ('28938', '0345391802', 5.666666666666667, 10.0),\n",
       " ('28938', '0971880107', 7.0, 6.0),\n",
       " ('28938', '0877733759', 5.666666666666667, 10.0),\n",
       " ('28938', '0310205719', 8.6666666666666661, 1.0),\n",
       " ('8167', '0345348036', 7.0, 7.0),\n",
       " ('71490', '0425101452', 7.666666666666667, 9.0),\n",
       " ('71490', '0425169693', 7.333333333333333, 5.0),\n",
       " ('71490', '0060096195', 8.0, 8.0),\n",
       " ('71490', '0345353145', 8.0, 7.0),\n",
       " ('71490', '0345378490', 8.3333333333333339, 8.0),\n",
       " ('71490', '0553580191', 7.0, 8.0),\n",
       " ('71490', '0446605239', 6.333333333333333, 7.0),\n",
       " ('71490', '0312978367', 8.3333333333333339, 9.0),\n",
       " ('71490', '0446608955', 8.3333333333333339, 8.0),\n",
       " ('71490', '059035342X', 8.0, 9.0),\n",
       " ('71490', '0553262505', 9.0, 6.0),\n",
       " ('71490', '0812967240', 7.666666666666667, 6.0),\n",
       " ('71490', '074343627X', 8.6666666666666661, 6.0),\n",
       " ('71490', '0345337662', 9.0, 8.0),\n",
       " ('71490', '0451456718', 9.0, 3.0),\n",
       " ('71490', '0765342987', 6.666666666666667, 10.0),\n",
       " ('236172', '0440236673', 9.3333333333333339, 9.0),\n",
       " ('236172', '0609804138', 8.6666666666666661, 10.0),\n",
       " ('236172', '0380710218', 9.0, 10.0),\n",
       " ('236172', '0446604844', 10.0, 8.0),\n",
       " ('236172', '0425178579', 9.6666666666666661, 10.0),\n",
       " ('236172', '0375760911', 9.0, 8.0),\n",
       " ('236172', '0671708635', 10.0, 4.0),\n",
       " ('236172', '0440225701', 9.0, 10.0),\n",
       " ('236172', '0312980159', 9.3333333333333339, 7.0),\n",
       " ('236172', '0374525641', 8.6666666666666661, 10.0),\n",
       " ('236172', '0446610100', 10.0, 9.0),\n",
       " ('236172', '0671027360', 10.0, 10.0),\n",
       " ('236172', '060980619X', 9.3333333333333339, 10.0),\n",
       " ('236172', '0451188454', 8.6666666666666661, 8.0),\n",
       " ('236172', '0446525774', 9.3333333333333339, 10.0),\n",
       " ('236172', '0449212602', 9.3333333333333339, 7.0),\n",
       " ('236172', '0385504209', 10.0, 10.0),\n",
       " ('236172', '0440234743', 9.0, 10.0),\n",
       " ('236172', '0061094129', 10.0, 8.0),\n",
       " ('94730', '0395977894', 7.333333333333333, 8.0),\n",
       " ('94730', '0316776963', 8.3333333333333339, 6.0),\n",
       " ('94730', '0671027344', 7.333333333333333, 9.0),\n",
       " ('94730', '0385512104', 7.666666666666667, 8.0),\n",
       " ('94730', '1573226521', 7.333333333333333, 5.0),\n",
       " ('94730', '0671755064', 7.333333333333333, 8.0),\n",
       " ('67111', '3426029553', 8.0, 8.0),\n",
       " ('4896', '0439064872', 7.333333333333333, 10.0),\n",
       " ('277478', '1558745718', 8.0, 8.0),\n",
       " ('221753', '1573220876', 9.3333333333333339, 9.0),\n",
       " ('221753', '1878424319', 9.6666666666666661, 5.0),\n",
       " ('221753', '0836218787', 9.0, 10.0),\n",
       " ('221753', '0060921145', 9.0, 10.0),\n",
       " ('221753', '0062502182', 9.6666666666666661, 8.0),\n",
       " ('163319', '0553573403', 7.666666666666667, 9.0),\n",
       " ('163319', '0812575717', 8.3333333333333339, 7.0),\n",
       " ('163319', '0425129586', 8.3333333333333339, 7.0),\n",
       " ('163319', '0553287346', 8.3333333333333339, 7.0),\n",
       " ('163319', '0553283685', 7.0, 9.0),\n",
       " ('259264', '044651652X', 7.0, 9.0),\n",
       " ('259264', '002542730X', 9.0, 7.0),\n",
       " ('141958', '0142001805', 8.0, 8.0),\n",
       " ('141958', '0671038567', 7.666666666666667, 6.0),\n",
       " ('141958', '0140071814', 7.333333333333333, 8.0),\n",
       " ('141958', '0440206154', 7.666666666666667, 7.0),\n",
       " ('141958', '0440236169', 7.666666666666667, 8.0),\n",
       " ('141958', '0312976275', 7.333333333333333, 7.0),\n",
       " ('141958', '0312971346', 7.333333333333333, 7.0)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_vector_itemItems[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# K-fold cross validation for collaborative filtering item-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def itemItems_KfoldsCV_clustering(small_userDict,small_isbnDict, dict_row, dict_col, CLUSTERS_USERS,CLUSTERS_ITEMS,\n",
    "                                                                            clusters_dict_row,clusters_dict_col,kk):\n",
    "\n",
    "    RMSE = []\n",
    "    #kk = 5\n",
    "    list_user = np.array(sorted(small_userDict.keys()))\n",
    "    b = len(small_userDict)//kk\n",
    "    \n",
    "    u_clusters, R_clusters, utility_DataFrame_clusters = computeMatrices(CLUSTERS_USERS,CLUSTERS_ITEMS,\n",
    "                                                                           CLUSTERS_USERS,CLUSTERS_ITEMS,\n",
    "                                                                            clusters_dict_row,clusters_dict_col)\n",
    "\n",
    "    for iterator in range(kk):\n",
    "\n",
    "        train_userDict, train_isbnDict, test_userDict, test_isbnDict, test =  selectSample(iterator,b,list_user,\n",
    "                                                                                           small_userDict, small_isbnDict)\n",
    "# use only train_userDict to create the utility matrix\n",
    "        u, R, small_utility_DataFrame = computeMatrices(train_userDict,small_isbnDict,small_userDict,small_isbnDict, dict_row, dict_col)\n",
    "# search users only in test_userDict\n",
    "        rmse_test, rmse_vector_itemItems = mainItemItemsRMSE_clustering(small_utility_DataFrame,utility_DataFrame_clusters,R_clusters, \n",
    "                                                             test_userDict, test_isbnDict,index_user_cluster,index_book_cluster,\n",
    "                                                             score_min=0, k=3)\n",
    "        print(\"Ok\")\n",
    "\n",
    "        RMSE.append(rmse_test)\n",
    "        \n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "small_userDict = {k:new_userDict[k] for k in list(new_userDict.keys())[:5000]}\n",
    "small_isbnDict = {k:new_isbnDict[k] for k in list(new_isbnDict.keys())[:5000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "small_isbnDict, small_userDict = createSampleDict(new_isbnDict, new_userDict, 20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n",
      "Ok\n",
      "Ok\n",
      "Ok\n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "RMSE = itemItems_KfoldsCV_clustering(small_userDict,small_isbnDict, dict_row, dict_col,CLUSTERS_USERS,CLUSTERS_ITEMS,\n",
    "                                                                            clusters_dict_row,clusters_dict_col, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse collaborative filtering item-based with clustering:  1.6367878478\n"
     ]
    }
   ],
   "source": [
    "print(\"rmse collaborative filtering item-based with clustering: \",np.mean(RMSE))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
