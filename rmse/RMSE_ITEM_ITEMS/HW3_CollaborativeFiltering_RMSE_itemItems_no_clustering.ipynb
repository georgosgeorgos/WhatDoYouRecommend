{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "import time\n",
    "import nltk\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import stem\n",
    "import sklearn.metrics\n",
    "from random import randint\n",
    "from numpy.linalg import norm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "with open('../new_userDict.json', 'r') as fp:\n",
    "    \n",
    "    new_userDict = json.load(fp)\n",
    "    \n",
    "with open('../new_isbnDict.json', 'r') as fp:\n",
    "    \n",
    "    new_isbnDict = json.load(fp)\n",
    "    \n",
    "with open('../dict_row.json', 'r') as fp:\n",
    "    \n",
    "    dict_row = json.load(fp)\n",
    "    \n",
    "with open('../dict_col.json', 'r') as fp:\n",
    "    \n",
    "    dict_col = json.load(fp)\n",
    "    \n",
    "        \n",
    "print(\"Ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def booksRatedUser(new_isbnDict, new_userDict, user_number, score):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    input:  new_userDict (Dict), user_number (int), score (int)\n",
    "    \n",
    "    action: select all books well rated by my user\n",
    "    \n",
    "    output: books_rated (list)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    books_rated = []\n",
    "    \n",
    "    for book in new_userDict[str(user_number)]:\n",
    "        \n",
    "        if int(new_userDict[str(user_number)][book]) > score:\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                new_isbnDict[book]\n",
    "                books_rated.append(book)\n",
    "                \n",
    "            except:\n",
    "                \n",
    "                continue\n",
    "            \n",
    "    return list(set(books_rated))\n",
    "\n",
    "\n",
    "def SimilarityBooks(utility_DataFrame, book_number, books_similar):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    input: utility_DataFrame (DataFrame), book_number (int), books_similar (List)\n",
    "    \n",
    "    action: compute cosine similarity between book_number and all the books in books_similar\n",
    "    \n",
    "    output: new_similarity (List of tuples)\n",
    "    \n",
    "    '''\n",
    "\n",
    "    x = utility_DataFrame[str(book_number)]\n",
    "    x_length = norm(x)\n",
    "    \n",
    "    y = utility_DataFrame[books_similar]\n",
    "    y_length = norm(utility_DataFrame[books_similar],axis=0)\n",
    "\n",
    "    \n",
    "    num = (y.T.values*x.values).sum(axis=1)\n",
    "    den = x_length*y_length\n",
    "\n",
    "    similarity = num/den\n",
    "    similarity = np.nan_to_num(similarity)\n",
    "    \n",
    "    d = list(zip(list(books_similar),similarity))\n",
    "    new_similarity = sorted(d, key=lambda tup: tup[1], reverse=True)\n",
    "    \n",
    "    return new_similarity\n",
    "\n",
    "def itemItemsRecommendation(new_similarity, user_number, book_number, k, new_userDict):\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    input:  new_similarity(List of tuples), new_isbnDict(Dict), k(int)\n",
    "    \n",
    "    action: compute mean similarity of the first k items\n",
    "    \n",
    "    output: recommendation (float)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    if len(new_similarity) < k:\n",
    "        \n",
    "        recommendation = np.mean([u[1] for u in new_similarity])\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        recommendation = np.mean([u[1] for u in new_similarity[:k]])\n",
    "        \n",
    "    \n",
    "    return recommendation\n",
    "\n",
    "\n",
    "def itemItemsScore(new_userDict, new_similarity, k, user_number):\n",
    "    \n",
    "    score = [int(new_userDict[str(user_number)][u[0]]) for u in new_similarity[:k]]\n",
    "    \n",
    "    if score == []:\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    return np.mean(score)\n",
    "\n",
    "\n",
    "def CollaborativeFilteringItemItemsRMSE(utility_DataFrame, new_userDict, new_isbnDict, user_number, score_min, book_number, k):\n",
    "    \n",
    "    books_rated_user = booksRatedUser(new_isbnDict, new_userDict, user_number,score_min)\n",
    "    \n",
    "    if books_rated_user == []:\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    new_similarity = SimilarityBooks(utility_DataFrame, book_number, books_rated_user)\n",
    "    \n",
    "    if new_similarity == []:\n",
    "\n",
    "        return None\n",
    "    \n",
    "    score = itemItemsScore(new_userDict, new_similarity[1:], k, user_number)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createSampleDict(new_isbnDict, new_userDict, t1, t2):\n",
    "    \n",
    "\n",
    "    small_isbnDict = {}\n",
    "\n",
    "    for book in new_isbnDict:\n",
    "\n",
    "        temp = new_isbnDict[book]\n",
    "        i = 0\n",
    "\n",
    "        for t in temp.values():\n",
    "            if t != \"0\":\n",
    "                i = i+1\n",
    "\n",
    "        if i >t1:\n",
    "\n",
    "            small_isbnDict[book] = new_isbnDict[book]   \n",
    "\n",
    "    small_userDict = {}\n",
    "\n",
    "    for user in new_userDict:\n",
    "\n",
    "        temp = new_userDict[user]\n",
    "        i = 0\n",
    "\n",
    "        for t in temp.values():\n",
    "            if t != \"0\":\n",
    "                i = i+1\n",
    "\n",
    "        if i >t2:\n",
    "\n",
    "            small_userDict[user] = new_userDict[user]\n",
    "            \n",
    "            \n",
    "    return small_isbnDict, small_userDict\n",
    "\n",
    "\n",
    "def computeMatrices(train_userDict,train_isbnDict,small_userDict,small_isbnDict, dict_row, dict_col):\n",
    "\n",
    "    n = len(small_isbnDict)\n",
    "    m = len(small_userDict)\n",
    "    \n",
    "    index = sorted(small_userDict.keys())\n",
    "    columns = sorted(small_isbnDict.keys())\n",
    "\n",
    "    dict_row = {k:v for v,k in enumerate(index)}\n",
    "    dict_col = {k:v for v,k in enumerate(columns)}\n",
    "\n",
    "    u = np.zeros((m,n)) \n",
    "    R = np.zeros((m,n))\n",
    "    for user in train_userDict:\n",
    "        for isbn in train_userDict[user]:\n",
    "            try:\n",
    "                u[dict_row[user]][dict_col[isbn]] = train_userDict[user][isbn]\n",
    "                R[dict_row[user]][dict_col[isbn]] = 1\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    for isbn in train_isbnDict:\n",
    "        for user in train_isbnDict[isbn]:\n",
    "            try:\n",
    "                u[dict_row[user]][dict_col[isbn]] = train_isbnDict[isbn][user]\n",
    "                R[dict_row[user]][dict_col[isbn]] = 1\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    small_utility_DataFrame = pd.DataFrame(u, index = index, columns = columns)\n",
    "    R = pd.DataFrame(R, index = index, columns = columns)\n",
    "\n",
    "    return u, R, small_utility_DataFrame\n",
    "\n",
    "\n",
    "def selectSample(i,b,list_user,small_userDict, small_isbnDict):\n",
    "\n",
    "    test_index = [k for k in range((i*b),(i+1)*b)]\n",
    "    train_index = [k for k in range(len(list_user)) if k not in test_index]\n",
    "\n",
    "    train = list_user[train_index]\n",
    "    test  = list_user[test_index]\n",
    "\n",
    "    train_userDict = {}\n",
    "    train_isbnDict = {isbn:{} for isbn in small_isbnDict}\n",
    "\n",
    "    for user in train:\n",
    "\n",
    "        train_userDict[user] = small_userDict[user]\n",
    "\n",
    "    for isbn in small_isbnDict:\n",
    "        for user in small_isbnDict[isbn]:\n",
    "\n",
    "            try:\n",
    "                train_userDict[user]\n",
    "                train_isbnDict[isbn][user] = small_isbnDict[isbn][user]\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "                \n",
    "    test_userDict = {}\n",
    "    test_isbnDict = {isbn:{} for isbn in small_isbnDict}\n",
    "\n",
    "    for user in test:\n",
    "\n",
    "        test_userDict[user] = small_userDict[user]\n",
    "\n",
    "    for isbn in small_isbnDict:\n",
    "        for user in small_isbnDict[isbn]:\n",
    "\n",
    "            try:\n",
    "                test_userDict[user]\n",
    "                test_isbnDict[isbn][user] = small_isbnDict[isbn][user]\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    return train_userDict, train_isbnDict, test_userDict, test_isbnDict, test\n",
    "\n",
    "\n",
    "#indices = [i for i in range(len(list_user))]\n",
    "#indices = np.array(indices)\n",
    "#k = 5\n",
    "#b = len(small_userDict)//k\n",
    "\n",
    "\n",
    "def selectSampleRandom(indices,b,list_user,small_userDict, small_isbnDict):\n",
    "    \n",
    "    test_index = np.random.choice(indices, size = b, replace=False)\n",
    "    \n",
    "    indices = np.delete(indices,test_index)\n",
    "    \n",
    "    train_index = [k for k in range(len(list_user)) if k not in test_index]\n",
    "    \n",
    "\n",
    "    train = list_user[train_index]\n",
    "    test  = list_user[test_index]\n",
    "\n",
    "    train_userDict = {}\n",
    "    train_isbnDict = {isbn:{} for isbn in small_isbnDict}\n",
    "\n",
    "    for user in train:\n",
    "\n",
    "        train_userDict[user] = small_userDict[user]\n",
    "\n",
    "    for isbn in small_isbnDict:\n",
    "        for user in small_isbnDict[isbn]:\n",
    "\n",
    "            try:\n",
    "                train_userDict[user]\n",
    "                train_isbnDict[isbn][user] = small_isbnDict[isbn][user]\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    return train_userDict, train_isbnDict, test_userDict, test_isbnDict, test, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mainItemItemsRMSE(utility_DataFrame,R, new_userDict, new_isbnDict, score_min=0, k=3):\n",
    "    \n",
    "\n",
    "    rmse_dict = {j:{} for j in new_userDict.keys()}\n",
    "\n",
    "    for user in new_userDict:\n",
    "\n",
    "        for book in new_userDict[user]:\n",
    "\n",
    "            if new_userDict[user][book] != \"0\":\n",
    "\n",
    "                try:\n",
    "                    new_isbnDict[book]\n",
    "                    rmse_dict[user][book] = new_userDict[user][book]\n",
    "                except:\n",
    "\n",
    "                    continue\n",
    "\n",
    "    d = rmse_dict.keys()\n",
    "    v = []\n",
    "\n",
    "    for key in d:\n",
    "\n",
    "        if rmse_dict[key] == {}:\n",
    "\n",
    "            v.append(key)\n",
    "\n",
    "    for i in v:\n",
    "\n",
    "        del rmse_dict[i]\n",
    "\n",
    "    rmse_vector_itemItems = []\n",
    "    \n",
    "    i = 0\n",
    "    for user in rmse_dict:\n",
    "        \n",
    "        i = i+1\n",
    "        if i%1000 == 0:\n",
    "            \n",
    "            print(\"Pause\")\n",
    "            time.sleep(30)\n",
    "\n",
    "        for isbn in rmse_dict[user]:\n",
    "            \n",
    "            prediction_score = None\n",
    "            user_number = user\n",
    "            book_number = isbn\n",
    "            \n",
    "            try:\n",
    "                prediction_score = CollaborativeFilteringItemItemsRMSE(utility_DataFrame, new_userDict, new_isbnDict, \n",
    "                                                                   user_number, score_min, book_number, k)\n",
    "                true_score = utility_DataFrame[book_number][user_number]\n",
    "                \n",
    "                if prediction_score == None:\n",
    "                    \n",
    "                    term1 = utility_DataFrame[book_number]\n",
    "                    r1 = R[book_number]\n",
    "                    term1 = term1[r1 ==1]\n",
    "                    \n",
    "                    term2 = utility_DataFrame.loc[user_number]\n",
    "                    r2 = R.loc[user_number]\n",
    "                    term2 = term2[r2==1]\n",
    "                    \n",
    "                    prediction_score = (np.mean(term1) + np.mean(term2))/2\n",
    "            \n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            if prediction_score != None:\n",
    "\n",
    "                rmse_vector_itemItems.append(tuple([user_number, book_number, prediction_score, true_score]))\n",
    "\n",
    "\n",
    "    rmse = np.sqrt((np.array([u[2]-u[3] for u in rmse_vector_itemItems])**2).sum()/len(rmse_vector_itemItems))\n",
    "    \n",
    "    return rmse, rmse_vector_itemItems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pause\n",
      "Pause\n",
      "Pause\n"
     ]
    }
   ],
   "source": [
    "u, R, small_utility_DataFrame = computeMatrices(small_userDict,small_isbnDict,small_userDict,small_isbnDict,dict_row,dict_col)\n",
    "\n",
    "rmse_test, rmse_vector_itemItems = mainItemItemsRMSE(small_utility_DataFrame,R,small_userDict,small_isbnDict,score_min=0,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('183985', '0374199698', 5.840909090909091, 9.0),\n",
       " ('188513', '0312421702', 4.0, 9.0),\n",
       " ('188513', '034545104X', 9.0, 4.0),\n",
       " ('49061', '0385491026', 5.5, 8.0),\n",
       " ('167038', '0451210743', 2.6666666666666665, 8.0),\n",
       " ('226205', '0812513738', 7.333333333333333, 9.0),\n",
       " ('226205', '0399151648', 7.333333333333333, 6.0),\n",
       " ('226205', '0553264303', 7.0, 8.0),\n",
       " ('226205', '0671027646', 7.333333333333333, 8.0),\n",
       " ('226205', '0743411269', 7.333333333333333, 8.0),\n",
       " ('226205', '0399145885', 7.333333333333333, 8.0),\n",
       " ('226205', '0446343129', 7.333333333333333, 7.0),\n",
       " ('226205', '0425191729', 7.333333333333333, 7.0),\n",
       " ('226205', '0425177068', 7.333333333333333, 7.0),\n",
       " ('83587', '0440993717', 8.0, 7.0),\n",
       " ('83587', '0553211404', 7.0, 8.0),\n",
       " ('175822', '2253057843', 4.875, 6.0),\n",
       " ('33345', '0312870582', 2.6666666666666665, 4.0),\n",
       " ('77724', '0425158640', 6.923076923076923, 10.0),\n",
       " ('57109', '0816707987', 6.0, 8.0),\n",
       " ('170255', '0452284449', 5.0, 7.0),\n",
       " ('170255', '0156027321', 7.0, 5.0),\n",
       " ('31252', '0380813815', 6.896551724137931, 10.0),\n",
       " ('64197', '0099469626', 3.25, 6.0),\n",
       " ('174428', '0345443284', 4.0, 5.0),\n",
       " ('174428', '0345439244', 5.0, 3.0),\n",
       " ('174428', '0316569321', 4.0, 5.0),\n",
       " ('249096', '1567189644', 7.0, 10.0),\n",
       " ('249096', '0671250671', 10.0, 4.0),\n",
       " ('249096', '080411935X', 7.0, 10.0),\n",
       " ('143571', '0679731156', 9.0, 9.0),\n",
       " ('143571', '0451190157', 9.0, 9.0),\n",
       " ('246230', '0312973055', 6.35, 10.0),\n",
       " ('145413', '0452271401', 5.0, 5.0),\n",
       " ('278390', '044661257X', 7.0, 8.0),\n",
       " ('278390', '0688152449', 8.0, 7.0),\n",
       " ('175463', '0842329250', 9.0, 8.0),\n",
       " ('175463', '0842329129', 8.0, 9.0),\n",
       " ('258556', '0785268839', 10.0, 7.0),\n",
       " ('258556', '0811205460', 8.5, 10.0),\n",
       " ('258556', '0767904656', 10.0, 10.0),\n",
       " ('128622', '0684856603', 2.8888888888888893, 7.0),\n",
       " ('22503', '0380732238', 7.0, 8.0),\n",
       " ('22503', '0552147427', 7.0, 7.0),\n",
       " ('142584', '0679732241', 7.333333333333333, 10.0),\n",
       " ('142584', '067172262X', 8.3333333333333339, 7.0),\n",
       " ('142584', '0446611212', 8.0, 8.0),\n",
       " ('142584', '0451163524', 8.3333333333333339, 7.0),\n",
       " ('220490', '0552134619', 7.0, 5.0),\n",
       " ('220490', '1857989546', 5.0, 7.0),\n",
       " ('136136', '0425158594', 1.9117647058823528, 8.0),\n",
       " ('171295', '0553280414', 8.6666666666666661, 8.0),\n",
       " ('171295', '0061054909', 7.666666666666667, 10.0),\n",
       " ('171295', '0553278355', 8.6666666666666661, 9.0),\n",
       " ('171295', '067178501X', 8.3333333333333339, 8.0),\n",
       " ('171295', '0446386405', 8.3333333333333339, 8.0),\n",
       " ('171295', '0553212451', 8.6666666666666661, 7.0),\n",
       " ('174642', '0425178102', 8.0, 9.0),\n",
       " ('174642', '0842329129', 9.0, 8.0),\n",
       " ('85510', '0553288342', 8.0, 5.0),\n",
       " ('85510', '0812541642', 5.0, 8.0),\n",
       " ('75833', '3423128399', 10.0, 9.0),\n",
       " ('75833', '3257232608', 9.0, 10.0),\n",
       " ('114742', '0451167805', 5.794117647058823, 9.0),\n",
       " ('82608', '0312147015', 5.681818181818182, 7.0),\n",
       " ('234597', '0679879250', 9.3333333333333339, 9.0),\n",
       " ('234597', '0679745203', 9.3333333333333339, 9.0),\n",
       " ('234597', '0834802759', 9.3333333333333339, 10.0),\n",
       " ('234597', '8878192961', 9.3333333333333339, 10.0),\n",
       " ('234597', '0525455205', 9.3333333333333339, 10.0),\n",
       " ('234597', '0385482388', 9.6666666666666661, 8.0),\n",
       " ('234597', '0786869011', 10.0, 8.0),\n",
       " ('234597', '0553211404', 9.3333333333333339, 10.0),\n",
       " ('234597', '1857022076', 9.3333333333333339, 10.0),\n",
       " ('234597', '0894717960', 9.3333333333333339, 10.0),\n",
       " ('16036', '0380730448', 8.0, 10.0),\n",
       " ('16036', '0345348109', 10.0, 8.0),\n",
       " ('84897', '0375752501', 6.0, 7.0),\n",
       " ('84897', '0060934417', 5.666666666666667, 8.0),\n",
       " ('84897', '044991089X', 6.666666666666667, 5.0),\n",
       " ('84897', '0671776134', 6.666666666666667, 5.0),\n",
       " ('24778', '0552134627', 4.861111111111111, 9.0),\n",
       " ('249732', '0553211277', 3.0, 6.0),\n",
       " ('55687', '0345339738', 7.3936170212765955, 10.0),\n",
       " ('123257', '0671640453', 8.6666666666666661, 10.0),\n",
       " ('123257', '0440967694', 8.6666666666666661, 10.0),\n",
       " ('123257', '0553213415', 9.3333333333333339, 8.0),\n",
       " ('123257', '0671670689', 9.3333333333333339, 9.0),\n",
       " ('123257', '0380010038', 8.6666666666666661, 10.0),\n",
       " ('123257', '0380759497', 8.6666666666666661, 10.0),\n",
       " ('123257', '0671027344', 8.6666666666666661, 10.0),\n",
       " ('123257', '0439064864', 9.3333333333333339, 10.0),\n",
       " ('123257', '0440998050', 8.6666666666666661, 10.0),\n",
       " ('123257', '0064472272', 8.6666666666666661, 6.0),\n",
       " ('123257', '0671759345', 9.0, 10.0),\n",
       " ('123257', '0440219329', 8.6666666666666661, 5.0),\n",
       " ('123257', '0679781587', 8.3333333333333339, 10.0),\n",
       " ('123257', '0886778190', 8.6666666666666661, 10.0),\n",
       " ('123257', '067100767X', 9.3333333333333339, 8.0),\n",
       " ('123257', '014028009X', 9.3333333333333339, 7.0)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_vector_itemItems[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# K-fold cross validation for collaborative filtering item-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def itemItems_KfoldsCV(small_userDict,small_isbnDict, dict_row, dict_col, kk):\n",
    "\n",
    "    RMSE = []\n",
    "    #kk = 5\n",
    "    list_user = np.array(sorted(small_userDict.keys()))\n",
    "    b = len(small_userDict)//kk\n",
    "\n",
    "    for iterator in range(kk):\n",
    "\n",
    "        train_userDict, train_isbnDict, test_userDict, test_isbnDict, test =  selectSample(iterator,b,list_user,\n",
    "                                                                                           small_userDict, small_isbnDict)\n",
    "# use only train_userDict to create the utility matrix\n",
    "        u, R, small_utility_DataFrame = computeMatrices(train_userDict,small_isbnDict,small_userDict,small_isbnDict, dict_row, dict_col)\n",
    "# search users only in test_userDict\n",
    "        rmse_test, rmse_vector_itemItems = mainItemItemsRMSE(small_utility_DataFrame,R, test_userDict, test_isbnDict, score_min=0, k=3)\n",
    "        print(\"Ok\")\n",
    "\n",
    "        RMSE.append(rmse_test)\n",
    "        \n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small_userDict = {k:new_userDict[k] for k in list(new_userDict.keys())[:5000]}\n",
    "small_isbnDict = {k:new_isbnDict[k] for k in list(new_isbnDict.keys())[:5000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#small_isbnDict, small_userDict = createSampleDict(new_isbnDict, new_userDict, 20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n",
      "Ok\n",
      "Ok\n",
      "Ok\n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "RMSE = itemItems_KfoldsCV(small_userDict,small_isbnDict, dict_row, dict_col, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse collaborative filtering item-based:  2.04692489866\n"
     ]
    }
   ],
   "source": [
    "print(\"rmse collaborative filtering item-based: \",np.mean(RMSE))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
