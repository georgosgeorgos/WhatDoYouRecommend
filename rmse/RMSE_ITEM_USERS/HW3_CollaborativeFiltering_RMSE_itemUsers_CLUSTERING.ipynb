{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import time\n",
    "import nltk\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import stem\n",
    "import sklearn.metrics\n",
    "from random import randint\n",
    "from numpy.linalg import norm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "with open('../new_userDict.json', 'r') as fp:\n",
    "    \n",
    "    new_userDict = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('../new_isbnDict.json', 'r') as fp:\n",
    "    \n",
    "    new_isbnDict = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('../dict_row.json', 'r') as fp:\n",
    "    \n",
    "    dict_row = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('../dict_col.json', 'r') as fp:\n",
    "    \n",
    "    dict_col = json.load(fp)\n",
    "    \n",
    "print(\"Ok\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "with open('../clustering/CLUSTERS_ITEMS.json', 'r') as fp:\n",
    "    \n",
    "    CLUSTERS_ITEMS = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('../clustering/CLUSTERS_USERS.json', 'r') as fp:\n",
    "    \n",
    "    CLUSTERS_USERS = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('../clustering/file/clusters_dict_row.json', 'r') as fp:\n",
    "    \n",
    "    clusters_dict_row = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('../clustering/file/clusters_dict_col.json', 'r') as fp:\n",
    "    \n",
    "    clusters_dict_col = json.load(fp)\n",
    "    \n",
    "print(\"Ok\") \n",
    "\n",
    "\n",
    "\n",
    "with open('../clustering/index_book_user_clusters/index_user_cluster.json', 'r') as fp:\n",
    "    \n",
    "    index_user_cluster = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('../clustering/index_book_user_clusters/index_book_cluster.json', 'r') as fp:\n",
    "    \n",
    "    index_book_cluster = json.load(fp)\n",
    "    \n",
    "print(\"Ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generateClustersUsingClustersNewDicts(clusters_new_isbnDict, index_user_cluster):\n",
    "\n",
    "    clusters_books = {k:{} for k in clusters_new_isbnDict}\n",
    "\n",
    "    for c_i in clusters_new_isbnDict:\n",
    "\n",
    "        for user in clusters_new_isbnDict[c_i]:\n",
    "\n",
    "            try:\n",
    "                c_u = index_user_cluster[user]\n",
    "\n",
    "                if c_u not in clusters_books[c_i]:\n",
    "\n",
    "                    clusters_books[c_i][c_u] = []\n",
    "\n",
    "                if float(clusters_new_isbnDict[c_i][user]) != 0.0:\n",
    "\n",
    "                    clusters_books[c_i][c_u].append(float(clusters_new_isbnDict[c_i][user]))\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    for c_b in clusters_books:\n",
    "\n",
    "        users_cluster = list(clusters_books[c_b].keys())\n",
    "\n",
    "        for c_u in users_cluster:\n",
    "\n",
    "            if clusters_books[c_b][c_u] == []:\n",
    "\n",
    "                del clusters_books[c_b][c_u]\n",
    "            else:\n",
    "                clusters_books[c_b][c_u] = np.mean(clusters_books[c_b][c_u])\n",
    "                \n",
    "                \n",
    "    return clusters_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ATTENTION!!!  different respect to usersHaveRatedBook(s)\n",
    "\n",
    "def usersHaveRatedBook(new_isbnDict, new_userDict, book_number, score):\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    input:  new_isbnDict (Dict), new_userDict (Dict), book_number (int), score (int)\n",
    "    \n",
    "    action: select all users that have given a good rating to book_number\n",
    "    \n",
    "    output: users_rated (list)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    users_rated = []\n",
    "    \n",
    "    for user in new_isbnDict[str(book_number)]:\n",
    "        \n",
    "        if float(new_isbnDict[str(book_number)][user]) > score:\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                new_userDict[user]\n",
    "                users_rated.append(user)\n",
    "                \n",
    "            except:\n",
    "                \n",
    "                continue\n",
    "            \n",
    "    return list(set(users_rated))\n",
    "\n",
    "\n",
    "def SimilarityUsers(utility_DataFrame, user_number, users_similar):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    input: utility_DataFrame (DataFrame), user_number (int), user_similar (List)\n",
    "    \n",
    "    action: compute cosine similarity between user_number and all the user in users_similar\n",
    "    \n",
    "    output: new_similarity (List of tuples)\n",
    "    \n",
    "    '''\n",
    "\n",
    "    x = utility_DataFrame.loc[str(user_number)]\n",
    "    x_length = norm(x)\n",
    "    \n",
    "    y = utility_DataFrame.loc[users_similar]\n",
    "    y_length = norm(utility_DataFrame.loc[users_similar],axis=1)\n",
    "\n",
    "    \n",
    "    num = (y.values*x.values).sum(axis=1)\n",
    "    den = x_length*y_length\n",
    "\n",
    "    similarity = num/den\n",
    "    similarity = np.nan_to_num(similarity)\n",
    "    \n",
    "    d = list(zip(list(users_similar),similarity))\n",
    "    new_similarity = sorted(d, key=lambda tup: tup[1], reverse=True)\n",
    "    \n",
    "    \n",
    "    return new_similarity\n",
    "\n",
    "def ItemUsersRecommendation(new_similarity, new_userDict, k):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    input:  new_similarity(List of tuples), new_userDict(Dict), score(int), k(int)\n",
    "    \n",
    "    action: recommend items using the ratings of similar users\n",
    "    \n",
    "    output: recommendation (Dict), books (Dict)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if new_similarity == []:\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    if len(new_similarity) > k:\n",
    "    \n",
    "        recommendation = np.mean([u[1] for u in new_similarity[:k]]) \n",
    "    \n",
    "    else:\n",
    "        \n",
    "        recommendation = np.mean([u[1] for u in new_similarity]) \n",
    "        \n",
    "    return recommendation\n",
    "\n",
    "\n",
    "def itemUsersScore(new_similarity,new_isbnDict, book_number, k):\n",
    "    \n",
    "    if new_similarity == []:\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    if len(new_similarity) > k:\n",
    "        \n",
    "        score = [float(new_isbnDict[str(book_number)][u[0]]) for u in new_similarity[:k] if u[1] !=0.0]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        score = [float(new_isbnDict[str(book_number)][u[0]]) for u in new_similarity if u[1] !=0.0]\n",
    "    \n",
    "    return np.mean(score)\n",
    "\n",
    "\n",
    "def CollaborativeFilteringItemUsersRMSE(utility_DataFrame, new_userDict, new_isbnDict, user_number, score_min, book_number, k):\n",
    "    \n",
    "    users_rated_book = usersHaveRatedBook(new_isbnDict, new_userDict, book_number, score_min)\n",
    "    \n",
    "    if users_rated_book == []:\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    new_similarity = SimilarityUsers(utility_DataFrame, user_number, users_rated_book)\n",
    "    \n",
    "    \n",
    "    if new_similarity == []:\n",
    "\n",
    "        return None\n",
    "    \n",
    "    score = itemUsersScore(new_similarity,new_isbnDict, book_number, k)\n",
    "    \n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert(user_number,book_number, index_user_cluster, index_book_cluster):\n",
    "    \n",
    "    user_cluster = index_user_cluster[user_number]\n",
    "    book_cluster = index_book_cluster[book_number]\n",
    "    \n",
    "    return user_cluster, book_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createSampleDict(new_isbnDict, new_userDict, t1, t2):\n",
    "    \n",
    "\n",
    "    small_isbnDict = {}\n",
    "\n",
    "    for book in new_isbnDict:\n",
    "\n",
    "        temp = new_isbnDict[book]\n",
    "        i = 0\n",
    "\n",
    "        for t in temp.values():\n",
    "            if t != \"0\":\n",
    "                i = i+1\n",
    "\n",
    "        if i >t1:\n",
    "\n",
    "            small_isbnDict[book] = new_isbnDict[book]   \n",
    "\n",
    "    small_userDict = {}\n",
    "\n",
    "    for user in new_userDict:\n",
    "\n",
    "        temp = new_userDict[user]\n",
    "        i = 0\n",
    "\n",
    "        for t in temp.values():\n",
    "            if t != \"0\":\n",
    "                i = i+1\n",
    "\n",
    "        if i >t2:\n",
    "\n",
    "            small_userDict[user] = new_userDict[user]\n",
    "            \n",
    "            \n",
    "    return small_isbnDict, small_userDict\n",
    "\n",
    "\n",
    "def computeMatrices(train_userDict,train_isbnDict,small_userDict,small_isbnDict, dict_row, dict_col):\n",
    "\n",
    "    n = len(small_isbnDict)\n",
    "    m = len(small_userDict)\n",
    "    \n",
    "    index = sorted(small_userDict.keys())\n",
    "    columns = sorted(small_isbnDict.keys())\n",
    "\n",
    "    dict_row = {k:v for v,k in enumerate(index)}\n",
    "    dict_col = {k:v for v,k in enumerate(columns)}\n",
    "\n",
    "    u = np.zeros((m,n)) \n",
    "    R = np.zeros((m,n))\n",
    "    for user in train_userDict:\n",
    "        for isbn in train_userDict[user]:\n",
    "            try:\n",
    "                u[dict_row[user]][dict_col[isbn]] = train_userDict[user][isbn]\n",
    "                R[dict_row[user]][dict_col[isbn]] = 1\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    for isbn in train_isbnDict:\n",
    "        for user in train_isbnDict[isbn]:\n",
    "            try:\n",
    "                u[dict_row[user]][dict_col[isbn]] = train_isbnDict[isbn][user]\n",
    "                R[dict_row[user]][dict_col[isbn]] = 1\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    small_utility_DataFrame = pd.DataFrame(u, index = index, columns = columns)\n",
    "    R = pd.DataFrame(R, index = index, columns = columns)\n",
    "\n",
    "    return u, R, small_utility_DataFrame\n",
    "\n",
    "\n",
    "def selectSample(i,b,list_user,small_userDict, small_isbnDict):\n",
    "\n",
    "    test_index = [k for k in range((i*b),(i+1)*b)]\n",
    "    train_index = [k for k in range(len(list_user)) if k not in test_index]\n",
    "\n",
    "    train = list_user[train_index]\n",
    "    test  = list_user[test_index]\n",
    "\n",
    "    train_userDict = {}\n",
    "    train_isbnDict = {isbn:{} for isbn in small_isbnDict}\n",
    "\n",
    "    for user in train:\n",
    "\n",
    "        train_userDict[user] = small_userDict[user]\n",
    "\n",
    "    for isbn in small_isbnDict:\n",
    "        for user in small_isbnDict[isbn]:\n",
    "\n",
    "            try:\n",
    "                train_userDict[user]\n",
    "                train_isbnDict[isbn][user] = small_isbnDict[isbn][user]\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "                \n",
    "    test_userDict = {}\n",
    "    test_isbnDict = {isbn:{} for isbn in small_isbnDict}\n",
    "\n",
    "    for user in test:\n",
    "\n",
    "        test_userDict[user] = small_userDict[user]\n",
    "\n",
    "    for isbn in small_isbnDict:\n",
    "        for user in small_isbnDict[isbn]:\n",
    "\n",
    "            try:\n",
    "                test_userDict[user]\n",
    "                test_isbnDict[isbn][user] = small_isbnDict[isbn][user]\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    return train_userDict, train_isbnDict, test_userDict, test_isbnDict, test\n",
    "\n",
    "\n",
    "#indices = [i for i in range(len(list_user))]\n",
    "#indices = np.array(indices)\n",
    "#k = 5\n",
    "#b = len(small_userDict)//k\n",
    "\n",
    "\n",
    "def selectSampleRandom(indices,b,list_user,small_userDict, small_isbnDict):\n",
    "    \n",
    "    test_index = np.random.choice(indices, size = b, replace=False)\n",
    "    \n",
    "    indices = np.delete(indices,test_index)\n",
    "    \n",
    "    train_index = [k for k in range(len(list_user)) if k not in test_index]\n",
    "    \n",
    "\n",
    "    train = list_user[train_index]\n",
    "    test  = list_user[test_index]\n",
    "\n",
    "    train_userDict = {}\n",
    "    train_isbnDict = {isbn:{} for isbn in small_isbnDict}\n",
    "\n",
    "    for user in train:\n",
    "\n",
    "        train_userDict[user] = small_userDict[user]\n",
    "\n",
    "    for isbn in small_isbnDict:\n",
    "        for user in small_isbnDict[isbn]:\n",
    "\n",
    "            try:\n",
    "                train_userDict[user]\n",
    "                train_isbnDict[isbn][user] = small_isbnDict[isbn][user]\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    return train_userDict, train_isbnDict, test_userDict, test_isbnDict, test, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mainItemUsersRMSE_clustering(utility_DataFrame,utility_DataFrame_clusters,R_clusters, new_userDict, new_isbnDict,\n",
    "                                 index_user_cluster, index_book_cluster, score_min=0, k=3, zeros= \"n\"):\n",
    "    \n",
    "\n",
    "    rmse_dict = {j:{} for j in new_userDict.keys()}\n",
    "\n",
    "    for user in new_userDict:\n",
    "\n",
    "        for book in new_userDict[user]:\n",
    "\n",
    "            if new_userDict[user][book] != \"0\":\n",
    "                try:\n",
    "                    new_isbnDict[book]\n",
    "                    rmse_dict[user][book] = new_userDict[user][book]\n",
    "                except:\n",
    "                    continue\n",
    "                    \n",
    "            if new_userDict[user][book] == \"0\" and zeros != \"n\":  #if this is true score_min = -1\n",
    "                try:\n",
    "                    new_isbnDict[book]\n",
    "                    rmse_dict[user][book] = \"1\"\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    d = rmse_dict.keys()\n",
    "    v = []\n",
    "\n",
    "    for key in d:\n",
    "\n",
    "        if rmse_dict[key] == {}:\n",
    "\n",
    "            v.append(key)\n",
    "\n",
    "    for i in v:\n",
    "\n",
    "        del rmse_dict[i]\n",
    "\n",
    "    rmse_vector_itemUsers = []\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for user in rmse_dict:\n",
    "        \n",
    "        i = i+1\n",
    "        \n",
    "        if i%1000 == 0:\n",
    "            \n",
    "            print(\"Pause\")\n",
    "            print(np.sqrt((np.array([u[2]-u[3] for u in rmse_vector_itemUsers])**2).sum()/len(rmse_vector_itemUsers)))\n",
    "            time.sleep(30)\n",
    "\n",
    "        for isbn in rmse_dict[user]:\n",
    "            \n",
    "            prediction_score = None\n",
    "            user_number = user\n",
    "            book_number = isbn\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                prediction_score = CollaborativeFilteringItemUsersRMSE(utility_DataFrame, new_userDict, new_isbnDict, \n",
    "                                                                   user_number, score_min, book_number, k)\n",
    "                true_score = utility_DataFrame[book_number][user_number]\n",
    "            \n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            if prediction_score == None:\n",
    "                \n",
    "                user_cluster, book_cluster = convert(user_number,book_number, index_user_cluster, index_book_cluster)\n",
    "                \n",
    "                if R_clusters[book_cluster][user_cluster] == 1:\n",
    "                \n",
    "                    prediction_score = utility_DataFrame_clusters[book_cluster][user_cluster]\n",
    "                    true_score = utility_DataFrame[book_number][user_number]\n",
    "\n",
    "            #print(true_score,prediction_score)\n",
    "\n",
    "            if prediction_score != None:\n",
    "\n",
    "                rmse_vector_itemUsers.append(tuple([user_number, book_number, prediction_score, true_score]))\n",
    "\n",
    "\n",
    "    rmse = np.sqrt((np.array([u[2]-u[3] for u in rmse_vector_itemUsers])**2).sum()/len(rmse_vector_itemUsers))\n",
    "    \n",
    "    return rmse, rmse_vector_itemUsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small_isbnDict, small_userDict = createSampleDict(new_isbnDict, new_userDict, 20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u_clusters, R_clusters, utility_DataFrame_clusters = computeMatrices(CLUSTERS_USERS,CLUSTERS_ITEMS,\n",
    "                                                                           CLUSTERS_USERS,CLUSTERS_ITEMS,\n",
    "                                                                            clusters_dict_row,clusters_dict_col)\n",
    "\n",
    "u, R, utility_DataFrame = computeMatrices(small_userDict,small_isbnDict,new_userDict,new_isbnDict,dict_row,dict_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rmse_test, rmse_vector_itemUsers = mainItemUsersRMSE_clustering(utility_DataFrame,utility_DataFrame_clusters,R_clusters,\n",
    "                                                                small_userDict,small_isbnDict,\n",
    "                                                                index_user_cluster,index_book_cluster,\n",
    "                                                                score_min=0,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2766', '0440219078', 8.0, 8.0),\n",
       " ('2766', '0440204194', 9.0, 8.0),\n",
       " ('2766', '0684801221', 10.0, 10.0),\n",
       " ('2766', '0440211263', 8.6666666666666661, 8.0),\n",
       " ('2766', '0449005615', 9.3333333333333339, 9.0),\n",
       " ('2766', '0767902521', 8.3333333333333339, 8.0),\n",
       " ('2766', '0440221595', 8.6666666666666661, 8.0),\n",
       " ('2766', '0440237688', 9.0, 7.0),\n",
       " ('2766', '0679751602', 7.333333333333333, 6.0),\n",
       " ('2766', '0060958022', 7.666666666666667, 8.0),\n",
       " ('2766', '0971880107', 5.666666666666667, 6.0),\n",
       " ('2766', '0553279912', 7.333333333333333, 7.0),\n",
       " ('2766', '0446611867', 8.6666666666666661, 7.0),\n",
       " ('2766', '0316666343', 8.3333333333333339, 9.0),\n",
       " ('2766', '014034294X', 8.3333333333333339, 9.0),\n",
       " ('2766', '0425178102', 7.0, 5.0),\n",
       " ('2766', '0446310786', 10.0, 10.0),\n",
       " ('2766', '1558745718', 8.3333333333333339, 7.0),\n",
       " ('2766', '044048474X', 7.666666666666667, 7.0),\n",
       " ('2766', '0385508417', 9.0, 7.0),\n",
       " ('2766', '0446516538', 6.0, 6.0),\n",
       " ('2766', '0670030643', 7.666666666666667, 8.0),\n",
       " ('162001', '0140265686', 7.666666666666667, 8.0),\n",
       " ('162001', '0070212570', 7.666666666666667, 7.0),\n",
       " ('162001', '0446387878', 8.0, 10.0),\n",
       " ('162001', '0553258001', 8.3333333333333339, 9.0),\n",
       " ('162001', '0312195516', 6.333333333333333, 8.0),\n",
       " ('162001', '0142001430', 8.3333333333333339, 8.0),\n",
       " ('162001', '0679751602', 7.666666666666667, 7.0),\n",
       " ('7841', '0385486804', 8.3333333333333339, 9.0),\n",
       " ('7841', '0812550757', 8.3333333333333339, 8.0),\n",
       " ('7841', '0316769487', 8.3333333333333339, 7.0),\n",
       " ('7841', '0060987103', 8.6666666666666661, 9.0),\n",
       " ('7841', '0446310786', 7.666666666666667, 5.0),\n",
       " ('7841', '0451163966', 9.3333333333333339, 9.0),\n",
       " ('7841', '0767902890', 10.0, 10.0),\n",
       " ('7841', '0679721886', 8.6666666666666661, 10.0),\n",
       " ('7841', '0679734775', 8.3333333333333339, 9.0),\n",
       " ('7841', '014034294X', 8.6666666666666661, 8.0),\n",
       " ('7841', '0140185216', 10.0, 10.0),\n",
       " ('7841', '0553274295', 9.3333333333333339, 9.0),\n",
       " ('253668', '1573227331', 8.6666666666666661, 10.0),\n",
       " ('253668', '0451191145', 9.3333333333333339, 8.0),\n",
       " ('253668', '0877733759', 9.6666666666666661, 10.0),\n",
       " ('52256', '0345413350', 7.666666666666667, 5.0),\n",
       " ('52256', '0804106304', 8.3333333333333339, 8.0),\n",
       " ('52256', '0553262505', 7.333333333333333, 3.0),\n",
       " ('21368', '0099727412', 8.3333333333333339, 8.0),\n",
       " ('21368', '0099279274', 7.666666666666667, 4.0),\n",
       " ('158254', '0060959037', 8.3333333333333339, 8.0),\n",
       " ('158254', '0345337662', 9.0, 8.0),\n",
       " ('158254', '0060930535', 8.0, 9.0),\n",
       " ('158254', '0375703861', 9.3333333333333339, 10.0),\n",
       " ('158254', '0609804138', 8.6666666666666661, 8.0),\n",
       " ('158254', '0385335482', 6.666666666666667, 6.0),\n",
       " ('158254', '0375756981', 9.0, 8.0),\n",
       " ('158254', '0679442405', 9.3333333333333339, 10.0),\n",
       " ('158254', '0316769487', 9.0, 8.0),\n",
       " ('158254', '0060928336', 7.666666666666667, 8.0),\n",
       " ('158254', '0345436911', 8.3333333333333339, 9.0),\n",
       " ('158254', '0452269571', 9.0, 8.0),\n",
       " ('158254', '060980619X', 9.0, 10.0),\n",
       " ('158254', '0452280621', 6.333333333333333, 7.0),\n",
       " ('158254', '0786885688', 7.666666666666667, 7.0),\n",
       " ('158254', '0156027321', 8.3333333333333339, 8.0),\n",
       " ('158254', '0375727132', 7.333333333333333, 8.0),\n",
       " ('158254', '0804106304', 8.0, 7.0),\n",
       " ('158254', '0380012863', 8.0, 8.0),\n",
       " ('143837', '0439139600', 10.0, 10.0),\n",
       " ('143837', '0449003787', 9.6666666666666661, 10.0),\n",
       " ('143837', '080410526X', 8.3333333333333339, 8.0),\n",
       " ('143837', '0425169863', 9.3333333333333339, 8.0),\n",
       " ('143837', '0060927569', 7.666666666666667, 9.0),\n",
       " ('143837', '0449221482', 9.6666666666666661, 10.0),\n",
       " ('143837', '0312990456', 9.6666666666666661, 10.0),\n",
       " ('143837', '043936213X', 10.0, 10.0),\n",
       " ('143837', '0553561618', 7.666666666666667, 8.0),\n",
       " ('143837', '0425154092', 9.6666666666666661, 9.0),\n",
       " ('143837', '0385479565', 9.0, 7.0),\n",
       " ('143837', '0449223604', 9.0, 10.0),\n",
       " ('143837', '0425158616', 9.0, 8.0),\n",
       " ('198930', '0345370775', 8.6666666666666661, 7.0),\n",
       " ('198930', '0439139600', 9.3333333333333339, 10.0),\n",
       " ('198930', '0345335465', 8.0, 8.0),\n",
       " ('198930', '031242227X', 9.3333333333333339, 10.0),\n",
       " ('198930', '0441005489', 8.0, 8.0),\n",
       " ('198930', '0679781587', 8.6666666666666661, 7.0),\n",
       " ('198930', '0345313860', 8.3333333333333339, 8.0),\n",
       " ('198930', '0064471837', 9.0, 10.0),\n",
       " ('198930', '0380789019', 8.6666666666666661, 9.0),\n",
       " ('198930', '0441005764', 7.666666666666667, 8.0),\n",
       " ('198930', '0804106304', 9.3333333333333339, 9.0),\n",
       " ('198930', '0380977788', 8.3333333333333339, 10.0),\n",
       " ('198930', '0064407667', 8.3333333333333339, 10.0),\n",
       " ('16634', '0553562738', 8.6666666666666661, 8.0),\n",
       " ('16634', '0679448594', 8.0, 8.0),\n",
       " ('16634', '0451166892', 9.6666666666666661, 10.0),\n",
       " ('16634', '0446677450', 7.666666666666667, 3.0),\n",
       " ('16634', '0440213525', 7.333333333333333, 7.0),\n",
       " ('16634', '0345422317', 8.0, 8.0)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_vector_itemUsers[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# K-fold cross validation for collaborative filtering user-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def itemUsers_KfoldsCV_clustering(small_userDict,small_isbnDict, dict_row, dict_col,CLUSTERS_USERS,CLUSTERS_ITEMS,\n",
    "                                                                            clusters_dict_row,clusters_dict_col, kk):\n",
    "\n",
    "    RMSE = []\n",
    "    \n",
    "    list_user = np.array(sorted(small_userDict.keys()))\n",
    "    b = len(small_userDict)//kk\n",
    "    \n",
    "    u_clusters, R_clusters, utility_DataFrame_clusters = computeMatrices(CLUSTERS_USERS,CLUSTERS_ITEMS,\n",
    "                                                                           CLUSTERS_USERS,CLUSTERS_ITEMS,\n",
    "                                                                            clusters_dict_row,clusters_dict_col)\n",
    "\n",
    "    for iterator in range(kk):\n",
    "\n",
    "        train_userDict, train_isbnDict, test_userDict, test_isbnDict, test =  selectSample(iterator,b,list_user,\n",
    "                                                                                           small_userDict, small_isbnDict)\n",
    "\n",
    "        u, R, small_utility_DataFrame = computeMatrices(train_userDict,small_isbnDict,small_userDict,small_isbnDict,dict_row,dict_col)\n",
    "\n",
    "        rmse_test, rmse_vector_itemUsers = mainItemUsersRMSE_clustering(small_utility_DataFrame,utility_DataFrame_clusters,R_clusters, \n",
    "                                                             test_userDict, test_isbnDict,index_user_cluster,index_book_cluster,\n",
    "                                                             score_min=0, k=3)\n",
    "        print(\"Ok\")\n",
    "\n",
    "        RMSE.append(rmse_test)\n",
    "        \n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "small_userDict = {k:new_userDict[k] for k in list(new_userDict.keys())[:5000]}\n",
    "small_isbnDict = {k:new_isbnDict[k] for k in list(new_isbnDict.keys())[:5000] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pause\n",
      "1.24302093629\n",
      "Pause\n",
      "1.2230951783\n",
      "Pause\n",
      "1.22064005137\n",
      "Ok\n",
      "Pause\n",
      "1.18027283173\n",
      "Pause\n",
      "1.17665939392\n",
      "Pause\n",
      "1.16800211558\n",
      "Ok\n",
      "Pause\n",
      "1.23725059508\n",
      "Pause\n",
      "1.1997828053\n",
      "Pause\n",
      "1.20466398197\n",
      "Ok\n",
      "Pause\n",
      "1.18887286193\n",
      "Pause\n",
      "1.20751138263\n",
      "Pause\n",
      "1.19235177416\n",
      "Ok\n",
      "Pause\n",
      "1.19091298041\n",
      "Pause\n",
      "1.19009579166\n",
      "Pause\n",
      "1.17096646174\n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "RMSE = itemUsers_KfoldsCV_clustering(new_userDict,new_isbnDict, dict_row, dict_col,CLUSTERS_USERS,CLUSTERS_ITEMS,\n",
    "                                                                            clusters_dict_row,clusters_dict_col, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse collaborative filtering user-based with clustering:  1.19090725471\n"
     ]
    }
   ],
   "source": [
    "print(\"rmse collaborative filtering user-based with clustering: \",np.mean(RMSE))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
