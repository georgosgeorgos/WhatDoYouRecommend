{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "import time\n",
    "import nltk\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import stem\n",
    "import sklearn.metrics\n",
    "from random import randint\n",
    "from numpy.linalg import norm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "with open('../new_userDict.json', 'r') as fp:\n",
    "    \n",
    "    new_userDict = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('../new_isbnDict.json', 'r') as fp:\n",
    "    \n",
    "    new_isbnDict = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('../dict_row.json', 'r') as fp:\n",
    "    \n",
    "    dict_row = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('../dict_col.json', 'r') as fp:\n",
    "    \n",
    "    dict_col = json.load(fp)\n",
    "    \n",
    "print(\"Ok\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ATTENTION!!!  different respect to usersHaveRatedBook(s)\n",
    "\n",
    "def usersHaveRatedBook(new_isbnDict, new_userDict, book_number, score):\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    input:  new_isbnDict (Dict), new_userDict (Dict), book_number (int), score (int)\n",
    "    \n",
    "    action: select all users that have given a good rating to book_number\n",
    "    \n",
    "    output: users_rated (list)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    users_rated = []\n",
    "    \n",
    "    for user in new_isbnDict[str(book_number)]:\n",
    "        \n",
    "        if int(new_isbnDict[str(book_number)][user]) > score:\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                new_userDict[user]\n",
    "                users_rated.append(user)\n",
    "                \n",
    "            except:\n",
    "                \n",
    "                continue\n",
    "            \n",
    "    return list(set(users_rated))\n",
    "\n",
    "\n",
    "def SimilarityUsers(utility_DataFrame, user_number, users_similar):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    input: utility_DataFrame (DataFrame), user_number (int), user_similar (List)\n",
    "    \n",
    "    action: compute cosine similarity between user_number and all the user in users_similar\n",
    "    \n",
    "    output: new_similarity (List of tuples)\n",
    "    \n",
    "    '''\n",
    "\n",
    "    x = utility_DataFrame.loc[str(user_number)]\n",
    "    x_length = norm(x)\n",
    "    \n",
    "    y = utility_DataFrame.loc[users_similar]\n",
    "    y_length = norm(utility_DataFrame.loc[users_similar],axis=1)\n",
    "\n",
    "    \n",
    "    num = (y.values*x.values).sum(axis=1)\n",
    "    den = x_length*y_length\n",
    "\n",
    "    similarity = num/den\n",
    "    similarity = np.nan_to_num(similarity)\n",
    "    \n",
    "    d = list(zip(list(users_similar),similarity))\n",
    "    new_similarity = sorted(d, key=lambda tup: tup[1], reverse=True)\n",
    "    \n",
    "    \n",
    "    return new_similarity\n",
    "\n",
    "def ItemUsersRecommendation(new_similarity, new_userDict, k):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    input:  new_similarity(List of tuples), new_userDict(Dict), score(int), k(int)\n",
    "    \n",
    "    action: recommend items using the ratings of similar users\n",
    "    \n",
    "    output: recommendation (Dict), books (Dict)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if new_similarity == []:\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    if len(new_similarity) > k:\n",
    "    \n",
    "        recommendation = np.mean([u[1] for u in new_similarity[:k]]) \n",
    "    \n",
    "    else:\n",
    "        \n",
    "        recommendation = np.mean([u[1] for u in new_similarity]) \n",
    "        \n",
    "    return recommendation\n",
    "\n",
    "\n",
    "def itemUsersScore(new_similarity,new_isbnDict, book_number, k):\n",
    "    \n",
    "    if new_similarity == []:\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    if len(new_similarity) > k:\n",
    "        \n",
    "        score = [int(new_isbnDict[str(book_number)][u[0]]) for u in new_similarity[:k] if u[1] !=0.0]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        score = [int(new_isbnDict[str(book_number)][u[0]]) for u in new_similarity if u[1] !=0.0]\n",
    "    \n",
    "    return np.mean(score)\n",
    "\n",
    "\n",
    "def CollaborativeFilteringItemUsersRMSE(utility_DataFrame, new_userDict, new_isbnDict, user_number, score_min, book_number, k):\n",
    "    \n",
    "    users_rated_book = usersHaveRatedBook(new_isbnDict, new_userDict, book_number, score_min)\n",
    "    \n",
    "    if users_rated_book == []:\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    new_similarity = SimilarityUsers(utility_DataFrame, user_number, users_rated_book)\n",
    "    \n",
    "    \n",
    "    if new_similarity == []:\n",
    "\n",
    "        return None\n",
    "    \n",
    "    score = itemUsersScore(new_similarity,new_isbnDict, book_number, k)\n",
    "    \n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createSampleDict(new_isbnDict, new_userDict, t1, t2):\n",
    "    \n",
    "\n",
    "    small_isbnDict = {}\n",
    "\n",
    "    for book in new_isbnDict:\n",
    "\n",
    "        temp = new_isbnDict[book]\n",
    "        i = 0\n",
    "\n",
    "        for t in temp.values():\n",
    "            if t != \"0\":\n",
    "                i = i+1\n",
    "\n",
    "        if i >t1:\n",
    "\n",
    "            small_isbnDict[book] = new_isbnDict[book]   \n",
    "\n",
    "    small_userDict = {}\n",
    "\n",
    "    for user in new_userDict:\n",
    "\n",
    "        temp = new_userDict[user]\n",
    "        i = 0\n",
    "\n",
    "        for t in temp.values():\n",
    "            if t != \"0\":\n",
    "                i = i+1\n",
    "\n",
    "        if i >t2:\n",
    "\n",
    "            small_userDict[user] = new_userDict[user]\n",
    "            \n",
    "            \n",
    "    return small_isbnDict, small_userDict\n",
    "\n",
    "\n",
    "def computeMatrices(train_userDict,train_isbnDict,small_userDict,small_isbnDict, dict_row, dict_col):\n",
    "\n",
    "    n = len(small_isbnDict)\n",
    "    m = len(small_userDict)\n",
    "    \n",
    "    index = sorted(small_userDict.keys())\n",
    "    columns = sorted(small_isbnDict.keys())\n",
    "\n",
    "    dict_row = {k:v for v,k in enumerate(index)}\n",
    "    dict_col = {k:v for v,k in enumerate(columns)}\n",
    "\n",
    "    u = np.zeros((m,n)) \n",
    "    R = np.zeros((m,n))\n",
    "    for user in train_userDict:\n",
    "        for isbn in train_userDict[user]:\n",
    "            try:\n",
    "                u[dict_row[user]][dict_col[isbn]] = train_userDict[user][isbn]\n",
    "                R[dict_row[user]][dict_col[isbn]] = 1\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    for isbn in train_isbnDict:\n",
    "        for user in train_isbnDict[isbn]:\n",
    "            try:\n",
    "                u[dict_row[user]][dict_col[isbn]] = train_isbnDict[isbn][user]\n",
    "                R[dict_row[user]][dict_col[isbn]] = 1\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    small_utility_DataFrame = pd.DataFrame(u, index = index, columns = columns)\n",
    "    R = pd.DataFrame(R, index = index, columns = columns)\n",
    "\n",
    "    return u, R, small_utility_DataFrame\n",
    "\n",
    "\n",
    "def selectSample(i,b,list_user,small_userDict, small_isbnDict):\n",
    "\n",
    "    test_index = [k for k in range((i*b),(i+1)*b)]\n",
    "    train_index = [k for k in range(len(list_user)) if k not in test_index]\n",
    "\n",
    "    train = list_user[train_index]\n",
    "    test  = list_user[test_index]\n",
    "\n",
    "    train_userDict = {}\n",
    "    train_isbnDict = {isbn:{} for isbn in small_isbnDict}\n",
    "\n",
    "    for user in train:\n",
    "\n",
    "        train_userDict[user] = small_userDict[user]\n",
    "\n",
    "    for isbn in small_isbnDict:\n",
    "        for user in small_isbnDict[isbn]:\n",
    "\n",
    "            try:\n",
    "                train_userDict[user]\n",
    "                train_isbnDict[isbn][user] = small_isbnDict[isbn][user]\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "                \n",
    "    test_userDict = {}\n",
    "    test_isbnDict = {isbn:{} for isbn in small_isbnDict}\n",
    "\n",
    "    for user in test:\n",
    "\n",
    "        test_userDict[user] = small_userDict[user]\n",
    "\n",
    "    for isbn in small_isbnDict:\n",
    "        for user in small_isbnDict[isbn]:\n",
    "\n",
    "            try:\n",
    "                test_userDict[user]\n",
    "                test_isbnDict[isbn][user] = small_isbnDict[isbn][user]\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    return train_userDict, train_isbnDict, test_userDict, test_isbnDict, test\n",
    "\n",
    "\n",
    "#indices = [i for i in range(len(list_user))]\n",
    "#indices = np.array(indices)\n",
    "#k = 5\n",
    "#b = len(small_userDict)//k\n",
    "\n",
    "\n",
    "def selectSampleRandom(indices,b,list_user,small_userDict, small_isbnDict):\n",
    "    \n",
    "    test_index = np.random.choice(indices, size = b, replace=False)\n",
    "    \n",
    "    indices = np.delete(indices,test_index)\n",
    "    \n",
    "    train_index = [k for k in range(len(list_user)) if k not in test_index]\n",
    "    \n",
    "\n",
    "    train = list_user[train_index]\n",
    "    test  = list_user[test_index]\n",
    "\n",
    "    train_userDict = {}\n",
    "    train_isbnDict = {isbn:{} for isbn in small_isbnDict}\n",
    "\n",
    "    for user in train:\n",
    "\n",
    "        train_userDict[user] = small_userDict[user]\n",
    "\n",
    "    for isbn in small_isbnDict:\n",
    "        for user in small_isbnDict[isbn]:\n",
    "\n",
    "            try:\n",
    "                train_userDict[user]\n",
    "                train_isbnDict[isbn][user] = small_isbnDict[isbn][user]\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    return train_userDict, train_isbnDict, test_userDict, test_isbnDict, test, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mainItemUsersRMSE(utility_DataFrame, R, new_userDict, new_isbnDict, score_min=0, k=3):\n",
    "    \n",
    "\n",
    "    rmse_dict = {j:{} for j in new_userDict.keys()}\n",
    "\n",
    "    for user in new_userDict:\n",
    "\n",
    "        for book in new_userDict[user]:\n",
    "\n",
    "            if new_userDict[user][book] != \"0\":\n",
    "\n",
    "                try:\n",
    "                    new_isbnDict[book]\n",
    "                    rmse_dict[user][book] = new_userDict[user][book]\n",
    "                except:\n",
    "\n",
    "                    continue\n",
    "\n",
    "    d = rmse_dict.keys()\n",
    "    v = []\n",
    "\n",
    "    for key in d:\n",
    "\n",
    "        if rmse_dict[key] == {}:\n",
    "\n",
    "            v.append(key)\n",
    "\n",
    "    for i in v:\n",
    "\n",
    "        del rmse_dict[i]\n",
    "\n",
    "    rmse_vector_itemUsers = []\n",
    "    \n",
    "    #i = 0\n",
    "    \n",
    "    for user in rmse_dict:\n",
    "        \n",
    "        #i = i+1\n",
    "        #if i%1000 == 0:\n",
    "            \n",
    "        #    print(\"Pause\")\n",
    "        #    time.sleep(30)\n",
    "\n",
    "        for isbn in rmse_dict[user]:\n",
    "            \n",
    "            prediction_score = None\n",
    "            user_number = user\n",
    "            book_number = isbn\n",
    "            \n",
    "            try:\n",
    "                prediction_score = CollaborativeFilteringItemUsersRMSE(utility_DataFrame, new_userDict, new_isbnDict, \n",
    "                                                                   user_number, score_min, book_number, k)\n",
    "                \n",
    "                #print(prediction_score)\n",
    "                true_score = utility_DataFrame[book_number][user_number]\n",
    "                \n",
    "                if prediction_score == None:\n",
    "                    \n",
    "                    term1 = utility_DataFrame[book_number]\n",
    "                    r1 = R[book_number]\n",
    "                    term1 = term1[r1 ==1]\n",
    "                    \n",
    "                    term2 = utility_DataFrame.loc[user_number]\n",
    "                    r2 = R.loc[user_number]\n",
    "                    term2 = term2[r2==1]\n",
    "                    \n",
    "                    prediction_score = (np.mean(term1) + np.mean(term2))/2\n",
    "            \n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            if prediction_score != None:\n",
    "\n",
    "                rmse_vector_itemUsers.append(tuple([user_number, book_number, prediction_score, true_score]))\n",
    "\n",
    "\n",
    "    rmse = np.sqrt((np.array([u[2]-u[3] for u in rmse_vector_itemUsers])**2).sum()/len(rmse_vector_itemUsers))\n",
    "    \n",
    "    return rmse, rmse_vector_itemUsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u, R, small_utility_DataFrame = computeMatrices(small_userDict,small_isbnDict,small_userDict,small_isbnDict,dict_row,dict_col)\n",
    "\n",
    "rmse_test, rmse_vector_itemUsers = mainItemUsersRMSE(small_utility_DataFrame,R,small_userDict,small_isbnDict,score_min=0,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmse_vector_itemUsers[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# K-fold cross validation for collaborative filtering user-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def itemUsers_KfoldsCV(small_userDict,small_isbnDict, dict_row, dict_col, kk):\n",
    "\n",
    "    RMSE = []\n",
    "    #kk = 5\n",
    "    list_user = np.array(sorted(small_userDict.keys()))\n",
    "    b = len(small_userDict)//kk\n",
    "\n",
    "    for iterator in range(kk):\n",
    "\n",
    "        train_userDict, train_isbnDict, test_userDict, test_isbnDict, test =  selectSample(iterator,b,list_user,\n",
    "                                                                                           small_userDict, small_isbnDict)\n",
    "\n",
    "        u, R, small_utility_DataFrame = computeMatrices(train_userDict,small_isbnDict,small_userDict,small_isbnDict,dict_row,dict_col)\n",
    "\n",
    "        rmse_test, rmse_vector_itemUsers = mainItemUsersRMSE(small_utility_DataFrame,R,test_userDict,test_isbnDict,score_min=0,k=3)\n",
    "        print(\"Ok\")\n",
    "\n",
    "        RMSE.append(rmse_test)\n",
    "        \n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small_userDict = {k:new_userDict[k] for k in list(new_userDict.keys())[:5000]}\n",
    "small_isbnDict = {k:new_isbnDict[k] for k in list(new_isbnDict.keys())[:5000] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "small_isbnDict, small_userDict = createSampleDict(new_isbnDict, new_userDict, 20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n",
      "Ok\n",
      "Ok\n",
      "Ok\n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "RMSE = itemUsers_KfoldsCV(new_userDict,new_isbnDict, dict_row, dict_col, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse collaborative filtering user-based:  1.19140763006\n"
     ]
    }
   ],
   "source": [
    "print(\"rmse collaborative filtering user-based: \",np.mean(RMSE))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
