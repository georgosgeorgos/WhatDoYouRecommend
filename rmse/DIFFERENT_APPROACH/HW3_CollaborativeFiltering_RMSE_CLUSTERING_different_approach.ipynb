{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "import time\n",
    "import nltk\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import stem\n",
    "import sklearn.metrics\n",
    "from random import randint\n",
    "from numpy.linalg import norm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "with open('../../new_userDict.json', 'r') as fp:\n",
    "    \n",
    "    new_userDict = json.load(fp)\n",
    "    \n",
    "with open('../../new_isbnDict.json', 'r') as fp:\n",
    "    \n",
    "    new_isbnDict = json.load(fp)\n",
    "    \n",
    "with open('../../dict_row.json', 'r') as fp:\n",
    "    \n",
    "    dict_row = json.load(fp)\n",
    "    \n",
    "with open('../../dict_col.json', 'r') as fp:\n",
    "    \n",
    "    dict_col = json.load(fp)\n",
    "    \n",
    "        \n",
    "print(\"Ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "with open('../../clustering/CLUSTERS_ITEMS.json', 'r') as fp:\n",
    "    \n",
    "    CLUSTERS_ITEMS = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('../../clustering/CLUSTERS_USERS.json', 'r') as fp:\n",
    "    \n",
    "    CLUSTERS_USERS = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('../../clustering/file/clusters_dict_row.json', 'r') as fp:\n",
    "    \n",
    "    clusters_dict_row = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('../../clustering/file/clusters_dict_col.json', 'r') as fp:\n",
    "    \n",
    "    clusters_dict_col = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('../../clustering/cluster_book_dict.json', 'r') as fp:\n",
    "    \n",
    "    cluster_book_dict = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('../../clustering/cluster_users_dict.json', 'r') as fp:\n",
    "    \n",
    "    cluster_users_dict = json.load(fp)\n",
    "    \n",
    "print(\"Ok\") \n",
    "\n",
    "\n",
    "\n",
    "with open('../../clustering/index_book_user_clusters/index_user_cluster.json', 'r') as fp:\n",
    "    \n",
    "    index_user_cluster = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('../../clustering/index_book_user_clusters/index_book_cluster.json', 'r') as fp:\n",
    "    \n",
    "    index_book_cluster = json.load(fp)\n",
    "    \n",
    "print(\"Ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I take books inside the cluster book and also rated by user inside user cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert(user_number,book_number, index_user_cluster, index_book_cluster):\n",
    "    \n",
    "    user_cluster = index_user_cluster[str(user_number)]\n",
    "    book_cluster = index_book_cluster[str(book_number)]\n",
    "    \n",
    "    return user_cluster, book_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createSampleDict(new_isbnDict, new_userDict, t1, t2):\n",
    "    \n",
    "\n",
    "    small_isbnDict = {}\n",
    "\n",
    "    for book in new_isbnDict:\n",
    "\n",
    "        temp = new_isbnDict[book]\n",
    "        i = 0\n",
    "\n",
    "        for t in temp.values():\n",
    "            if t != \"0\":\n",
    "                i = i+1\n",
    "\n",
    "        if i >t1:\n",
    "\n",
    "            small_isbnDict[book] = new_isbnDict[book]   \n",
    "\n",
    "    small_userDict = {}\n",
    "\n",
    "    for user in new_userDict:\n",
    "\n",
    "        temp = new_userDict[user]\n",
    "        i = 0\n",
    "\n",
    "        for t in temp.values():\n",
    "            if t != \"0\":\n",
    "                i = i+1\n",
    "\n",
    "        if i >t2:\n",
    "\n",
    "            small_userDict[user] = new_userDict[user]\n",
    "            \n",
    "            \n",
    "    return small_isbnDict, small_userDict\n",
    "\n",
    "\n",
    "def computeMatrices(train_userDict,train_isbnDict,small_userDict,small_isbnDict, dict_row, dict_col):\n",
    "\n",
    "    n = len(small_isbnDict)\n",
    "    m = len(small_userDict)\n",
    "    \n",
    "    index = sorted(small_userDict.keys())\n",
    "    columns = sorted(small_isbnDict.keys())\n",
    "\n",
    "    dict_row = {k:v for v,k in enumerate(index)}\n",
    "    dict_col = {k:v for v,k in enumerate(columns)}\n",
    "\n",
    "    u = np.zeros((m,n)) \n",
    "    R = np.zeros((m,n))\n",
    "    for user in train_userDict:\n",
    "        for isbn in train_userDict[user]:\n",
    "            try:\n",
    "                u[dict_row[user]][dict_col[isbn]] = train_userDict[user][isbn]\n",
    "                R[dict_row[user]][dict_col[isbn]] = 1\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    for isbn in train_isbnDict:\n",
    "        for user in train_isbnDict[isbn]:\n",
    "            try:\n",
    "                u[dict_row[user]][dict_col[isbn]] = train_isbnDict[isbn][user]\n",
    "                R[dict_row[user]][dict_col[isbn]] = 1\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    small_utility_DataFrame = pd.DataFrame(u, index = index, columns = columns)\n",
    "    R = pd.DataFrame(R, index = index, columns = columns)\n",
    "\n",
    "    return u, R, small_utility_DataFrame\n",
    "\n",
    "\n",
    "def selectSample(i,b,list_user,small_userDict, small_isbnDict):\n",
    "\n",
    "    test_index = [k for k in range((i*b),(i+1)*b)]\n",
    "    train_index = [k for k in range(len(list_user)) if k not in test_index]\n",
    "\n",
    "    train = list_user[train_index]\n",
    "    test  = list_user[test_index]\n",
    "\n",
    "    train_userDict = {}\n",
    "    train_isbnDict = {isbn:{} for isbn in small_isbnDict}\n",
    "\n",
    "    for user in train:\n",
    "\n",
    "        train_userDict[user] = small_userDict[user]\n",
    "\n",
    "    for isbn in small_isbnDict:\n",
    "        for user in small_isbnDict[isbn]:\n",
    "\n",
    "            try:\n",
    "                train_userDict[user]\n",
    "                train_isbnDict[isbn][user] = small_isbnDict[isbn][user]\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "                \n",
    "    test_userDict = {}\n",
    "    test_isbnDict = {isbn:{} for isbn in small_isbnDict}\n",
    "\n",
    "    for user in test:\n",
    "\n",
    "        test_userDict[user] = small_userDict[user]\n",
    "\n",
    "    for isbn in small_isbnDict:\n",
    "        for user in small_isbnDict[isbn]:\n",
    "\n",
    "            try:\n",
    "                test_userDict[user]\n",
    "                test_isbnDict[isbn][user] = small_isbnDict[isbn][user]\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    return train_userDict, train_isbnDict, test_userDict, test_isbnDict, test\n",
    "\n",
    "\n",
    "#indices = [i for i in range(len(list_user))]\n",
    "#indices = np.array(indices)\n",
    "#k = 5\n",
    "#b = len(small_userDict)//k\n",
    "\n",
    "\n",
    "def selectSampleRandom(indices,b,list_user,small_userDict, small_isbnDict):\n",
    "    \n",
    "    test_index = np.random.choice(indices, size = b, replace=False)\n",
    "    \n",
    "    indices = np.delete(indices,test_index)\n",
    "    \n",
    "    train_index = [k for k in range(len(list_user)) if k not in test_index]\n",
    "    \n",
    "\n",
    "    train = list_user[train_index]\n",
    "    test  = list_user[test_index]\n",
    "\n",
    "    train_userDict = {}\n",
    "    train_isbnDict = {isbn:{} for isbn in small_isbnDict}\n",
    "\n",
    "    for user in train:\n",
    "\n",
    "        train_userDict[user] = small_userDict[user]\n",
    "\n",
    "    for isbn in small_isbnDict:\n",
    "        for user in small_isbnDict[isbn]:\n",
    "\n",
    "            try:\n",
    "                train_userDict[user]\n",
    "                train_isbnDict[isbn][user] = small_isbnDict[isbn][user]\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    return train_userDict, train_isbnDict, test_userDict, test_isbnDict, test, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# different approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mainClusteringRMSE(utility_DataFrame, utility_DataFrame_clusters,R_clusters, \n",
    "                                 new_userDict, new_isbnDict,\n",
    "                                 index_user_cluster, index_book_cluster,zeros = \"n\"):\n",
    "    \n",
    "\n",
    "    rmse_dict = {j:{} for j in new_userDict.keys()}\n",
    "\n",
    "    for user in new_userDict:\n",
    "\n",
    "        for book in new_userDict[user]:\n",
    "\n",
    "            if new_userDict[user][book] != \"0\":\n",
    "\n",
    "                try:\n",
    "                    new_isbnDict[book][user]\n",
    "                    rmse_dict[user][book] = new_userDict[user][book]\n",
    "                except:\n",
    "                    continue\n",
    "                    \n",
    "            if new_userDict[user][book] == \"0\" and zeros != \"n\":\n",
    "                try:\n",
    "                    new_isbnDict[book]\n",
    "                    rmse_dict[user][book] = \"1\"\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    d = rmse_dict.keys()\n",
    "    v = []\n",
    "\n",
    "    for key in d:\n",
    "\n",
    "        if rmse_dict[key] == {}:\n",
    "\n",
    "            v.append(key)\n",
    "\n",
    "    for i in v:\n",
    "\n",
    "        del rmse_dict[i]\n",
    "\n",
    "    rmse_vector = []\n",
    "    \n",
    "    for user in rmse_dict:\n",
    "\n",
    "        for isbn in rmse_dict[user]:\n",
    "            \n",
    "            prediction_score = None\n",
    "            user_number = user\n",
    "            book_number = isbn\n",
    "            \n",
    "            try:\n",
    "                user_cluster, book_cluster = convert(user_number,book_number, index_user_cluster, index_book_cluster)\n",
    "                \n",
    "                if R_clusters[book_cluster][user_cluster] == 1.0:\n",
    "                    \n",
    "                    prediction_score = utility_DataFrame_clusters[book_cluster][user_cluster]\n",
    "                    true_score = utility_DataFrame[book_number][user_number]\n",
    "                    \n",
    "                if prediction_score == None:\n",
    "                    \n",
    "                    term1 = utility_DataFrame_clusters[book_cluster]\n",
    "                    r1 = R_clusters[book_cluster]\n",
    "                    term1 = term1[r1 ==1]\n",
    "                    \n",
    "                    term2 = utility_DataFrame_clusters.loc[user_cluster]\n",
    "                    r2 = R_clusters.loc[user_cluster]\n",
    "                    term2 = term2[r2==1]\n",
    "                    \n",
    "                    prediction_score = (np.mean(term1) + np.mean(term2))/2\n",
    "            \n",
    "            except:\n",
    "                prediction_score = None\n",
    "                \n",
    "            if prediction_score != None:    \n",
    "                \n",
    "                rmse_vector.append(tuple([user_number, book_number, prediction_score, true_score]))\n",
    "\n",
    "\n",
    "    rmse = np.sqrt((np.array([u[2]-u[3] for u in rmse_vector])**2).sum()/len(rmse_vector))\n",
    "    \n",
    "    return rmse, rmse_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u_clusters, R_clusters, utility_DataFrame_clusters = computeMatrices(CLUSTERS_USERS,CLUSTERS_ITEMS,\n",
    "                                                                           CLUSTERS_USERS,CLUSTERS_ITEMS,\n",
    "                                                                            clusters_dict_row,clusters_dict_col)\n",
    "\n",
    "u, R, utility_DataFrame = computeMatrices(new_userDict,new_isbnDict,new_userDict,new_isbnDict,dict_row,dict_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rmse_test, rmse_vector = mainClusteringRMSE(utility_DataFrame, utility_DataFrame_clusters,R_clusters,\n",
    "                                                                new_userDict, new_isbnDict,\n",
    "                                                                index_user_cluster, index_book_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4098341175566782"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('268171', '0440218039', 9.6666666666666661, 9.0),\n",
       " ('268171', '0425183394', 8.5, 8.0),\n",
       " ('268171', '0804115435', 6.0, 6.0),\n",
       " ('268171', '080411160X', 8.5, 8.0),\n",
       " ('268171', '055326981X', 7.0, 7.0),\n",
       " ('268171', '0064472051', 10.0, 10.0),\n",
       " ('268171', '0804115419', 4.0, 4.0),\n",
       " ('268171', '0515095826', 5.0, 5.0),\n",
       " ('268171', '0441004016', 8.5, 9.0),\n",
       " ('231560', '0446601241', 5.0, 5.0),\n",
       " ('231560', '0451452011', 7.0, 7.0),\n",
       " ('231560', '0380001411', 7.0, 7.0),\n",
       " ('231560', '0061091316', 8.0, 8.0),\n",
       " ('231560', '0671463004', 6.5, 5.0),\n",
       " ('231560', '0345434803', 8.4000000000000004, 9.0),\n",
       " ('231560', '0061012491', 8.0, 8.0),\n",
       " ('231560', '0345313860', 7.1666666666649999, 9.0),\n",
       " ('265595', '0140444254', 7.0, 7.0),\n",
       " ('265595', '1853260495', 8.0, 8.0),\n",
       " ('265595', '0749305401', 8.0, 8.0),\n",
       " ('265595', '1853260363', 7.0, 7.0),\n",
       " ('265595', '0486264653', 9.0, 9.0),\n",
       " ('162641', '0446530743', 7.0, 7.0),\n",
       " ('162641', '0312272057', 8.0, 8.0),\n",
       " ('162641', '038550926X', 9.0, 9.0),\n",
       " ('162641', '0679419454', 6.0, 6.0),\n",
       " ('150431', '037329056X', 5.0, 5.0),\n",
       " ('150431', '0375703063', 9.0, 9.0),\n",
       " ('150431', '0440222656', 8.0, 8.0),\n",
       " ('150431', '0373290608', 6.0, 5.0),\n",
       " ('150431', '0425152367', 6.0, 6.0),\n",
       " ('154791', '0553268937', 9.0, 9.0),\n",
       " ('154791', '0060995084', 8.0, 8.0),\n",
       " ('154791', '0380722704', 8.0, 8.0),\n",
       " ('154791', '038073267X', 9.0, 9.0),\n",
       " ('154791', '0064405842', 8.0, 8.0),\n",
       " ('154791', '034543479X', 7.0, 7.0),\n",
       " ('154791', '0142001740', 8.0, 9.0),\n",
       " ('147045', '0226500624', 6.3333333333299997, 7.0),\n",
       " ('147045', '0312195516', 7.25, 8.0),\n",
       " ('147045', '0385312202', 5.0, 5.0),\n",
       " ('147045', '0060175400', 8.25, 10.0),\n",
       " ('147045', '0141002077', 6.3333333333299997, 5.0),\n",
       " ('147045', '0452282152', 7.7857142857142856, 9.0),\n",
       " ('147045', '0679426159', 2.5, 5.0),\n",
       " ('147045', '0374173133', 6.3333333333299997, 7.0),\n",
       " ('240677', '0060930535', 9.5, 9.0),\n",
       " ('240677', '0375701230', 6.0, 6.0),\n",
       " ('240677', '0805059555', 8.0, 8.0),\n",
       " ('240677', '0385319207', 8.0, 8.0),\n",
       " ('240677', '0060391626', 8.0, 10.0),\n",
       " ('240677', '1573222135', 6.0, 8.0),\n",
       " ('240677', '068485497X', 7.0, 7.0),\n",
       " ('240677', '0385472951', 8.0, 8.0),\n",
       " ('240677', '0802130208', 10.0, 10.0),\n",
       " ('240677', '0066214440', 9.0, 9.0),\n",
       " ('14667', '0316666009', 10.0, 10.0),\n",
       " ('14667', '0385504209', 7.666666666666667, 10.0),\n",
       " ('14667', '0385510438', 10.0, 10.0),\n",
       " ('14667', '0778320359', 3.5, 7.0),\n",
       " ('14667', '0525947914', 7.6666666666700003, 10.0),\n",
       " ('14667', '0385335377', 8.0, 8.0),\n",
       " ('14667', '0142001740', 5.75, 9.0),\n",
       " ('14667', '0316780812', 7.333333333333333, 9.0),\n",
       " ('14667', '0446532452', 7.6666666666700003, 3.0),\n",
       " ('14667', '0316735027', 9.0, 9.0),\n",
       " ('14667', '0670032808', 6.3333333333350001, 5.0),\n",
       " ('14667', '0446531332', 8.0, 8.0),\n",
       " ('14667', '0743446291', 8.0, 8.0),\n",
       " ('14667', '0316693200', 10.0, 10.0),\n",
       " ('14667', '0525947299', 7.6666666666700003, 10.0),\n",
       " ('92005', '9725752228', 8.0, 8.0),\n",
       " ('92005', '9727474381', 6.5, 9.0),\n",
       " ('92005', '9727591965', 9.0, 9.0),\n",
       " ('92005', '0552998834', 7.5555555555566665, 10.0),\n",
       " ('92005', '9722000020', 9.0, 9.0),\n",
       " ('169043', '0452257743', 5.0, 5.0),\n",
       " ('169043', '0425097609', 5.0, 5.0),\n",
       " ('169043', '0425099334', 5.0, 5.0),\n",
       " ('169043', '0345305183', 5.0, 5.0),\n",
       " ('169043', '0425097773', 5.0, 5.0),\n",
       " ('169043', '0440170842', 8.0, 8.0),\n",
       " ('169043', '0385472951', 5.0, 5.0),\n",
       " ('224206', '0821769286', 7.0, 7.0),\n",
       " ('224206', '0671827847', 5.0, 5.0),\n",
       " ('224206', '038079456X', 9.0, 9.0),\n",
       " ('110887', '0316789976', 8.0, 8.0),\n",
       " ('110887', '0375707972', 8.0, 8.0),\n",
       " ('110887', '0375411453', 5.0, 5.0),\n",
       " ('110887', '0440211263', 8.0, 6.0),\n",
       " ('110887', '044661162X', 5.0, 5.0),\n",
       " ('110887', '0061042943', 7.0, 7.0),\n",
       " ('110887', '0743201647', 7.0, 6.0),\n",
       " ('110887', '0394755596', 5.0, 5.0),\n",
       " ('110887', '0446678457', 5.0, 5.0),\n",
       " ('110887', '0767916069', 8.0, 8.0),\n",
       " ('110887', '0399146695', 5.0, 5.0),\n",
       " ('110887', '0553571834', 7.0, 8.0),\n",
       " ('110887', '0451209907', 8.0, 6.0),\n",
       " ('110887', '0141001828', 9.0, 9.0)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_vector[:100]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
