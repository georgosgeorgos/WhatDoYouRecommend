{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import stem\n",
    "from random import randint\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings_dataFrame = pd.read_csv(\"ratings_dataFrame.csv\", index_col=0, encoding= \"ISO-8859-1\")\n",
    "\n",
    "books_dataFrame = pd.read_csv(\"books_dataFrame.csv\", index_col=0,encoding= \"ISO-8859-1\")\n",
    "books_dataFrame_new = pd.read_csv(\"books_dataFrame_new.csv\", index_col=0,encoding= \"ISO-8859-1\")\n",
    "\n",
    "users_dataFrame = pd.read_csv(\"users_dataFrame.csv\", index_col=0, low_memory=False,encoding= \"ISO-8859-1\")\n",
    "\n",
    "\n",
    "with open('userDict.json', 'r') as fp:\n",
    "    \n",
    "    userDict = json.load(fp)\n",
    "    \n",
    "with open('isbnDict.json', 'r') as fp:\n",
    "    \n",
    "    isbnDict = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('featuresDict.json', 'r') as fp:\n",
    "    \n",
    "    featuresDict = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('books.json', 'r') as fp:\n",
    "    \n",
    "    books = json.load(fp)\n",
    "    \n",
    "with open('users.json', 'r') as fp:\n",
    "    \n",
    "    users = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('mostRated.json', 'r') as fp:\n",
    "    \n",
    "    f = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = set()\n",
    "\n",
    "def featuresExtraction(books_dataFrame_new, features):\n",
    "     \n",
    "    years = books_dataFrame_new[\"Year-Of-Publication\"].values\n",
    "    features.update(set(years))\n",
    "\n",
    "    authors = books_dataFrame_new[\"Book-Author\"].values\n",
    "    features.update(set(authors))\n",
    "\n",
    "    publishers = books_dataFrame_new[\"Publisher\"].values\n",
    "    features.update(set(publishers))\n",
    "    \n",
    "    return features\n",
    "    \n",
    "    #for isbn in books_dataFrame_new.index:\n",
    "\n",
    "     #   title = books_dataFrame_new.loc[isbn][\"Book-Title\"]\n",
    "\n",
    "      #  for t in title.split(\" \"):\n",
    "\n",
    "      #      features.add(t)\n",
    "\n",
    "       # author = books_dataFrame_new.loc[isbn][\"Book-Author\"]\n",
    "        #features.add(author)\n",
    "\n",
    "        #publisher = books_dataFrame_new.loc[isbn][\"Publisher\"]\n",
    "        #features.add(publisher)\n",
    "        \n",
    "    #return features\n",
    "\n",
    "features = featuresExtraction(books_dataFrame_new, features)\n",
    "\n",
    "featuresDict = {v:k for k,v in enumerate(features)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute feature vectors for items(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "books = {k:{} for k in books_dataFrame_new.index }\n",
    "\n",
    "for isbn in books:\n",
    "    #add a weight to each information of a book \n",
    "    year = books_dataFrame_new.loc[isbn][\"Year-Of-Publication\"]\n",
    "    books[isbn][year] =  0.1 \n",
    "    \n",
    "    author = books_dataFrame_new.loc[isbn][\"Book-Author\"]\n",
    "    books[isbn][author] =  1\n",
    "        \n",
    "    publisher =  books_dataFrame_new.loc[isbn][\"Publisher\"]\n",
    "    books[isbn][publisher] =  0.3\n",
    "    \n",
    "    \n",
    "#    title = books_dataFrame_new.loc[isbn][\"Book-Title\"].strip().split(\" \")\n",
    "    \n",
    "#    for word in title:\n",
    "        \n",
    "#        books[isbn][word] = books[isbn].get(word,0) + 1\n",
    "    \n",
    "    \n",
    "#    author = books_dataFrame_new.loc[isbn][\"Book-Author\"]\n",
    "#    books[isbn][author] = books[isbn].get(author,0) + 1\n",
    "        \n",
    "#    publisher =  books_dataFrame_new.loc[isbn][\"Publisher\"]\n",
    "#    books[isbn][publisher] = books[isbn].get(publisher,0) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute feature vectors for users(readers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create a dictionary \n",
    "#key ----> user-id \n",
    "#values ----> dict(feature,\"freq\" or \"weight\")\n",
    "users = {k:{} for k in userDict}\n",
    "\n",
    "\n",
    "for isbn in books:\n",
    "    \n",
    "    try:\n",
    "        for user in isbnDict[isbn]:\n",
    "            #t is a rating \n",
    "            t = int(isbnDict[isbn][user])\n",
    "            if t > 5:# take books rated more than 5\n",
    "                \n",
    "                for feature in books[isbn]:\n",
    "                                      #feature -- This is the Key to be searched in the dictionary                                                              # Floor Division \n",
    "                    users[user][feature] =  users[user].get(feature,0) + books[isbn][feature] + t//5# 0 otherwise\n",
    "        except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I want to recommend to a particular user  a generic book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I start selecting users(w) that have rated > 9  books(v) rated > 8  by my user.\n",
    "\n",
    "# After that I select books(z) rated > 9 by these users(w).\n",
    "\n",
    "# The idea is to obtain a small subset (< 1000) of probably relevant users and/or items and using those to compute similarity (user/users or user/items).\n",
    "\n",
    "# If use user/users you need to do another operation because from most similar users you have to select preferred books. The advantage is that the subset user/users (< 200) is smaller that in the case user/items(< 1000).\n",
    "\n",
    "# Euristically user/items seems a better method with this feature vector.\n",
    "\n",
    "\n",
    "# This is a Content Based method with buckets for users/items.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# select books rated by initial user\n",
    "def genericContentBasedUserItems(user_number, userDict, isbnDict, featuresDict,users,books):\n",
    "   \n",
    "    #store in v-vector isbn of books rated by user_number with rating bigger than 8\n",
    "    v = []\n",
    "\n",
    "    for key in userDict[user_number]:\n",
    "            #take books with rating bigger than 8\n",
    "        if int(userDict[user_number][key]) > 8:\n",
    "\n",
    "            v.append(key)\n",
    "\n",
    "# select users that have rated books rated by initial users at the same time\n",
    "    \n",
    "    #Store in w-vector users with the same books quoted good by initial user\n",
    "    w = []\n",
    "\n",
    "    for isbn in v:\n",
    "        for key in  isbnDict[isbn]:\n",
    "                                 #take books with rating bigger than 8 \n",
    "            if int(isbnDict[isbn][key]) > 8 and (key != user_number):\n",
    "\n",
    "                w.append(key)   \n",
    "\n",
    "    w = list(set(w))#take unique elements\n",
    "\n",
    "\n",
    "    # books quoted by users that have rated the book(s) rated by initial user\n",
    "\n",
    "    #storage in z books of users in w\n",
    "    z = []\n",
    "\n",
    "    for user in w:\n",
    "\n",
    "        for isbn in userDict[user]:\n",
    "\n",
    "            if int(userDict[user][isbn]) > 8:\n",
    "\n",
    "                z.append(isbn)\n",
    "\n",
    "    z = list(set(z))   \n",
    "    \n",
    "    X_myUser = np.zeros(len(featuresDict))\n",
    "    #matrix n x 173878, n= len(z) described above\n",
    "    X_items = np.zeros((len(z),len(featuresDict)))\n",
    "\n",
    "    #fill  first matrix\n",
    "    for feature in users[user_number]:\n",
    "\n",
    "        X_myUser[featuresDict[feature]] = users[user_number][feature]#see inside users dictionary\n",
    "\n",
    "    #fill second matrix\n",
    "    for j in range(len(z)):\n",
    "\n",
    "        try:\n",
    "            for feature in books[z[j]]:\n",
    "\n",
    "\n",
    "                X_items[j][featuresDict[feature]] = books[z[j]][feature] #see inside books dictionary\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "    # vectorized cosine similarity\n",
    "    \n",
    "    #matrix mult n x 173878, then sum the columns\n",
    "    num = (X_myUser*X_items).sum(axis=1)\n",
    "    #distance of vector X_myUser\n",
    "    d_myUser = np.sqrt((X_myUser**2).sum())\n",
    "    #distance of each vector in X_items\n",
    "    d_items = np.sqrt((X_items**2).sum(axis=1))\n",
    "\n",
    "    res = num/(d_myUser*d_items)\n",
    "               #list of pairs(value cosinesim, book in w)\n",
    "    f = sorted(zip(z,res), key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "    f1 = [] #take a subset of f\n",
    "    \n",
    "    for tu in f:\n",
    "            \n",
    "            \n",
    "        if tu[1] != 0.0 and not np.isnan(tu[1]):\n",
    "\n",
    "            f1.append(tu)\n",
    "\n",
    "    f1 = sorted(f1, key=lambda tup: tup[1], reverse=True)\n",
    "            #take the first 10 recommendations, tu[0] is always an isbn\n",
    "    recommendation = {user_number: [tu[0] for tu in f1[:10]]}\n",
    "    \n",
    "    return recommendation\n",
    "\n",
    "\n",
    "def genericContentBasedUserUsers(user_number, userDict, isbnDict, featuresDict,users,books):\n",
    "    \n",
    "    #store in v-vector isbn of books rated by user_number with rating bigger than 8\n",
    "    v = []\n",
    "\n",
    "    for key in userDict[user_number]:\n",
    "\n",
    "        if int(userDict[user_number][key]) > 8:\n",
    "\n",
    "            v.append(key)\n",
    "\n",
    "    # select users that have rated books rated by initial user        \n",
    "\n",
    "    w = []\n",
    "\n",
    "    for isbn in v:\n",
    "        for key in  isbnDict[isbn]:\n",
    "\n",
    "            if int(isbnDict[isbn][key]) > 8 and (key != user_number):\n",
    "\n",
    "                w.append(key)    \n",
    "\n",
    "    w = list(set(w))\n",
    "\n",
    "\n",
    "    X_myUser = np.zeros(len(featuresDict))\n",
    "\n",
    "    # others users\n",
    "    X_otherUsers = np.zeros((len(w),len(featuresDict)))\n",
    "\n",
    "\n",
    "    for feature in users[user_number]:\n",
    "\n",
    "        X_myUser[featuresDict[feature]] = users[user_number][feature]\n",
    "\n",
    "\n",
    "    for j in range(len(w)):\n",
    "\n",
    "        try:\n",
    "            for feature in users[w[j]]:\n",
    "\n",
    "                X_otherUsers[j][featuresDict[feature]] = users[w[j]][feature]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    num = (X_myUser*X_otherUsers).sum(axis=1)\n",
    "\n",
    "    d_myUser = np.sqrt((X_myUser**2).sum())\n",
    "    d_otherUsers = np.sqrt((X_otherUsers**2).sum(axis=1))\n",
    "\n",
    "    res = num/(d_myUser*d_otherUsers)\n",
    "    \n",
    "        #list of pairs(value cosinesim, book in w)\n",
    "    f = sorted(zip(w,res), key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "    Rated = userDict[user_number] \n",
    "\n",
    "    recommendation = {user_number: []}\n",
    "\n",
    "    for tup in f:\n",
    "\n",
    "        for book in userDict[tup[0]]:\n",
    "    #if that book is rated more than 8 and it's not in books rated by my initial user and if there is not in list inside recomm\n",
    "            if int(userDict[tup[0]][book]) > 8 and book not in Rated and book not in  recommendation[user_number]:\n",
    "\n",
    "                recommendation[user_number].append(book)\n",
    "\n",
    "            if len(recommendation[user_number]) > 10:\n",
    "\n",
    "                break\n",
    "            #stop loops--\n",
    "        if len(recommendation[user_number]) > 10:\n",
    "\n",
    "                break\n",
    "                \n",
    "    return recommendation\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print titles of recommended books generated by one of the functions above\n",
    "def userRecommendations(user_number,books_dataFrame, recommendation): \n",
    "    \n",
    "    for isbn in recommendation[user_number]:\n",
    "\n",
    "        try:\n",
    "            print(books_dataFrame.loc[isbn][\"Book-Title\"])\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    return None\n",
    "\n",
    "def userRatings(user_number, userDict,books_dataFrame):\n",
    "\n",
    "    for isbn in userDict[user_number]:\n",
    "\n",
    "        try:\n",
    "            if  int(userDict[user_number][isbn]) > 8:\n",
    "                print(books_dataFrame.loc[isbn][\"Book-Title\"])\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is not useful in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_user = sorted(userDict.keys())\n",
    "d_isbn = sorted(isbnDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ContentBasedSimilarity(user_number,featuresDict,users,books,z):\n",
    "\n",
    "    X_myUser = np.zeros(len(featuresDict))\n",
    "\n",
    "    X_items = np.zeros((len(z),len(featuresDict)))\n",
    "\n",
    "\n",
    "    for feature in users[user_number]:\n",
    "\n",
    "        X_myUser[featuresDict[feature]] = users[user_number][feature]\n",
    "\n",
    "    for j in range(len(z)):\n",
    "\n",
    "        try:\n",
    "            for feature in books[z[j]]:\n",
    "\n",
    "                X_items[j][featuresDict[feature]] = books[z[j]][feature]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    num = (X_myUser*X_items).sum(axis=1)\n",
    "\n",
    "    d_myUser = np.sqrt((X_myUser**2).sum())\n",
    "    d_items = np.sqrt((X_items**2).sum(axis=1))\n",
    "\n",
    "    res = num/(d_myUser*d_items)\n",
    "\n",
    "    f = list(zip(z,res))\n",
    "    \n",
    "    return f\n",
    "\n",
    "\n",
    "def mainContentBasedSimilarity(featuresDict,userDict,isbnDict,users,books,d_user,d_isbn,books_dataFrame,t):\n",
    "    \n",
    "    \n",
    "    print(\"Please choose a user and/or an item\\n\")\n",
    "    print(\"user or random user: \\n\")\n",
    "    user_number = input()\n",
    "    if user_number == \"\":   \n",
    "        user_number = None\n",
    "    print(\"item or random item: \\n\")\n",
    "    book_numbers = input()\n",
    "    if book_numbers == \"\":\n",
    "        book_numbers = None\n",
    "\n",
    "    if user_number != None or book_numbers != None: #case of a specific id-user o isbn book, given from input\n",
    "\n",
    "        if user_number == None:\n",
    "\n",
    "            n = randint(0,len(userDict))# random userid generator\n",
    "            user_number = d_user[n]\n",
    "\n",
    "        if book_numbers == None:\n",
    "\n",
    "            m = randint(0,len(isbnDict))#random isbn generator\n",
    "            book_numbers = d_isbn[m]\n",
    "            \n",
    "    else:\n",
    "            \n",
    "        n = randint(0,len(userDict))\n",
    "        user_number = d_user[n]\n",
    "        m = randint(0,len(isbnDict))\n",
    "        book_numbers = d_isbn[m]\n",
    "\n",
    "    z = book_numbers.split()\n",
    "\n",
    "    ff = ContentBasedSimilarity(user_number,featuresDict,users,books,z)\n",
    "    print(\"To user <\", user_number, \"> using a content based recommender system:\\n\")\n",
    "    for f in ff:\n",
    "        \n",
    "        nan = np.isnan(f[1])\n",
    "        print(f)\n",
    "\n",
    "        if float(f[1]) > t and not nan :\n",
    "            try:\n",
    "                rec = books_dataFrame.loc[f[0]][\"Book-Title\"]\n",
    "                print(\"we recommend <\", rec,\">\")\n",
    "            except:\n",
    "                print(\"we recommend <\", f[0],\">\")\n",
    "        else:\n",
    "            try:\n",
    "                rec = books_dataFrame.loc[f[0]][\"Book-Title\"]\n",
    "                print(\"we don't recommend <\", rec,\">\")\n",
    "            except:\n",
    "                print(\"we don't recommend <\", f[0],\">\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chooseUser(userDict, d_user):\n",
    "    \n",
    "    print(\"Please choose a user\\n\")\n",
    "    print(\"user or random user: \\n\")\n",
    "    user_number = input()\n",
    "    if user_number == \"\":\n",
    "        user_number = None\n",
    "    if user_number == None:\n",
    "        n = randint(0,len(userDict))\n",
    "        user_number = d_user[n]\n",
    "        return user_number\n",
    "    else:\n",
    "        return user_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#put together all the function defined above\n",
    "def mainContentBased(featuresDict,userDict,isbnDict,users,books,d_user,d_isbn,books_dataFrame,t):\n",
    "    \n",
    "    r = -1 # init  control variable\n",
    "    while r not in [1,2]:\n",
    "        \n",
    "        print(\"\\nPlease select a recommender system:\\n\")\n",
    "        print(\"1 Content Based user-items\\n\")\n",
    "        print(\"2 Content Based user-users\\n\") #need to choose  option 1 or 2\n",
    "        try:\n",
    "            r = int(input())\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if r == 1:\n",
    "        user_number = chooseUser(userDict,d_user)\n",
    "        recommendation = genericContentBasedUserItems(user_number, userDict, isbnDict, featuresDict,users,books)\n",
    "        if recommendation[user_number] == []:\n",
    "            print(\"We don't have a recommendation for you. We can only recommend the most popular and well rated books in the database:\\n\")\n",
    "            for i in f: \n",
    "                print(books_dataFrame[\"Book-Title\"][i[0]])\n",
    "            return None\n",
    "        print(\"For user <\",user_number,\"> we recommend using a content based approach:\\n\")\n",
    "        userRecommendations(user_number,books_dataFrame, recommendation)\n",
    "    elif r == 2:\n",
    "        user_number = chooseUser(userDict,d_user)\n",
    "        recommendation = genericContentBasedUserUsers(user_number, userDict, isbnDict, featuresDict,users,books)\n",
    "        if recommendation[user_number] == []:\n",
    "            print(\"We don't have a recommendation for user <\",user_number,\">. We can only recommend the most popular and well rated books in the database:\\n\")\n",
    "            for i in f:\n",
    "                print(books_dataFrame[\"Book-Title\"][i[0]])\n",
    "            return None\n",
    "        print(\"For user <\",user_number,\"> we recommend using a content based approach:\\n\")\n",
    "        userRecommendations(user_number,books_dataFrame, recommendation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want a recommendation?\n",
      "\n",
      "y\n",
      "n\n",
      "\n",
      "y\n",
      "\n",
      "Please select a recommender system:\n",
      "\n",
      "1 Content Based user-items\n",
      "\n",
      "2 Content Based user-users\n",
      "\n",
      "1\n",
      "Please choose a user\n",
      "\n",
      "user or random user: \n",
      "\n",
      "147839\n",
      "We don't have a recommendation for you. We can only recommend the most popular and well rated books in the database:\n",
      "\n",
      "Harry Potter and the Order of the Phoenix (Book 5)\n",
      "The Hobbit : The Enchanting Prelude to The Lord of the Rings\n",
      "To Kill a Mockingbird\n",
      "Harry Potter and the Sorcerer's Stone (Harry Potter (Paperback))\n",
      "Harry Potter and the Chamber of Secrets (Book 2)\n",
      "The Da Vinci Code\n",
      "The Catcher in the Rye\n",
      "The Five People You Meet in Heaven\n",
      "The Lovely Bones: A Novel\n",
      "Fahrenheit 451\n",
      "\n",
      "Please select a recommender system:\n",
      "\n",
      "1 Content Based user-items\n",
      "\n",
      "2 Content Based user-users\n",
      "\n",
      "2\n",
      "Please choose a user\n",
      "\n",
      "user or random user: \n",
      "\n",
      "147839\n",
      "We don't have a recommendation for user < 147839 >. We can only recommend the most popular and well rated books in the database:\n",
      "\n",
      "Harry Potter and the Order of the Phoenix (Book 5)\n",
      "The Hobbit : The Enchanting Prelude to The Lord of the Rings\n",
      "To Kill a Mockingbird\n",
      "Harry Potter and the Sorcerer's Stone (Harry Potter (Paperback))\n",
      "Harry Potter and the Chamber of Secrets (Book 2)\n",
      "The Da Vinci Code\n",
      "The Catcher in the Rye\n",
      "The Five People You Meet in Heaven\n",
      "The Lovely Bones: A Novel\n",
      "Fahrenheit 451\n",
      "\n",
      "Do you want a recommendation?\n",
      "\n",
      "y\n",
      "n\n",
      "\n",
      "n\n",
      "Bye\n"
     ]
    }
   ],
   "source": [
    "r = -1\n",
    "while True:\n",
    "    while r not in [\"y\",\"n\"]:\n",
    "        print(\"\\nDo you want a recommendation?\\n\")\n",
    "        print(\"y\")\n",
    "        print(\"n\\n\")\n",
    "        r = input()\n",
    "    if r == \"y\":\n",
    "        mainContentBased(featuresDict,userDict,isbnDict,users,books,d_user,d_isbn,books_dataFrame,0.2)\n",
    "        \n",
    "        try:\n",
    "            mainContentBased(featuresDict,userDict,isbnDict,users,books,d_user,d_isbn,books_dataFrame,0.2)\n",
    "        except:\n",
    "            print(\"I you are a new user (also known as Cold Star). We can only recommend to you the most popular books in our database:\\n\")\n",
    "            for i in f:# f is the return of  mostPopularBooksRecommendation\n",
    "                print(books_dataFrame[\"Book-Title\"][i[0]])\n",
    "        r = -1\n",
    "    else:\n",
    "        print(\"Bye\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mostPopularBooksRecommendation(isbnDict):\n",
    "    \n",
    "    mean_ratings_isbn = {k:[] for k in isbnDict} #dictionary of list of ratings given to a book \n",
    "    for isbn in mean_ratings_isbn:\n",
    "        for user in isbnDict[isbn]:\n",
    "            mean_ratings_isbn[isbn].append(int(isbnDict[isbn][user]))#add each rating given to a book\n",
    "            \n",
    "    f = [] #f is a list of list\n",
    "    for isbn in mean_ratings_isbn:\n",
    "                        #len of rating obtained\n",
    "        f.append([isbn,len(mean_ratings_isbn[isbn]),np.mean(mean_ratings_isbn[isbn])])\n",
    "    f = sorted(f, key=lambda tup: tup[1], reverse=True)\n",
    "    f = f[:100] #take the first 100 with the most amount of votes\n",
    "    f = sorted(f, key=lambda tup: tup[2], reverse=True)\n",
    "        #from those 100 take just 10 with the the highest average\n",
    "    f = f[:10]\n",
    "    \n",
    "    for i in f:\n",
    "        \n",
    "        print(books_dataFrame[\"Book-Title\"][i[0]])\n",
    "    \n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter and the Order of the Phoenix (Book 5)\n",
      "The Hobbit : The Enchanting Prelude to The Lord of the Rings\n",
      "To Kill a Mockingbird\n",
      "Harry Potter and the Sorcerer's Stone (Harry Potter (Paperback))\n",
      "Harry Potter and the Chamber of Secrets (Book 2)\n",
      "The Da Vinci Code\n",
      "The Catcher in the Rye\n",
      "The Five People You Meet in Heaven\n",
      "The Lovely Bones: A Novel\n",
      "Fahrenheit 451\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['043935806X', 334, 5.5718562874251498],\n",
       " ['0345339681', 281, 5.0071174377224201],\n",
       " ['0446310786', 389, 4.9203084832904889],\n",
       " ['059035342X', 571, 4.9001751313485116],\n",
       " ['0439064872', 351, 4.7293447293447297],\n",
       " ['0385504209', 883, 4.6523216308040771],\n",
       " ['0316769487', 403, 4.6352357320099253],\n",
       " ['0786868716', 427, 4.543325526932084],\n",
       " ['0316666343', 1295, 4.4687258687258691],\n",
       " ['0345342968', 321, 4.40809968847352]]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostPopularBooksRecommendation(isbnDict)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
