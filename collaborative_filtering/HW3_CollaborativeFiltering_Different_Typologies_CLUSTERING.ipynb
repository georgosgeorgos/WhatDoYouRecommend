{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import time\n",
    "import nltk\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import stem\n",
    "import sklearn.metrics\n",
    "from random import randint\n",
    "from numpy.linalg import norm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#ratings_dataFrame = pd.read_csv(\"../Preprocess/ratings_dataFrame.csv\", index_col=0)\n",
    "\n",
    "books_dataFrame = pd.read_csv(\"../Preprocess/books_dataFrame.csv\", index_col=0)\n",
    "\n",
    "#users_dataFrame = pd.read_csv(\"../Preprocess/users_dataFrame.csv\", index_col=0, low_memory=False)\n",
    "\n",
    "\n",
    "# select only users in userDict rated by more that three users with a non-zero rating\n",
    "\n",
    "with open('new_userDict.json', 'r') as fp:\n",
    "    \n",
    "    new_userDict = json.load(fp)\n",
    "    \n",
    "# select only books in isbnDict rated by more that three users with a non-zero rating    \n",
    "    \n",
    "with open('new_isbnDict.json', 'r') as fp:\n",
    "    \n",
    "    new_isbnDict = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('dict_row.json', 'r') as fp:\n",
    "    \n",
    "    dict_row = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('dict_col.json', 'r') as fp:\n",
    "    \n",
    "    dict_col = json.load(fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeMatrices(train_userDict,train_isbnDict,small_userDict,small_isbnDict, dict_row, dict_col):\n",
    "\n",
    "    n = len(small_isbnDict)\n",
    "    m = len(small_userDict)\n",
    "    \n",
    "    index = sorted(small_userDict.keys())\n",
    "    columns = sorted(small_isbnDict.keys())\n",
    "\n",
    "    dict_row = {k:v for v,k in enumerate(index)}\n",
    "    dict_col = {k:v for v,k in enumerate(columns)}\n",
    "\n",
    "    u = np.zeros((m,n)) \n",
    "    R = np.zeros((m,n))\n",
    "    for user in train_userDict:\n",
    "        for isbn in train_userDict[user]:\n",
    "            try:\n",
    "                u[dict_row[user]][dict_col[isbn]] = train_userDict[user][isbn]\n",
    "                R[dict_row[user]][dict_col[isbn]] = 1\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    for isbn in train_isbnDict:\n",
    "        for user in train_isbnDict[isbn]:\n",
    "            try:\n",
    "                u[dict_row[user]][dict_col[isbn]] = train_isbnDict[isbn][user]\n",
    "                R[dict_row[user]][dict_col[isbn]] = 1\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    small_utility_DataFrame = pd.DataFrame(u, index = index, columns = columns)\n",
    "    R = pd.DataFrame(R, index = index, columns = columns)\n",
    "\n",
    "    return u, R, small_utility_DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert(user_number,book_number, index_user_cluster, index_book_cluster):\n",
    "    \n",
    "    try:\n",
    "        user_cluster = index_user_cluster[user_number]\n",
    "    except:\n",
    "        print(\"key problem\")\n",
    "        return None\n",
    "    \n",
    "    if book_number != None:\n",
    "        \n",
    "        try:\n",
    "            book_cluster = index_book_cluster[book_number]\n",
    "            return user_cluster, book_cluster\n",
    "        except:\n",
    "            print(\"key problem\")\n",
    "            return None\n",
    "        \n",
    "    return user_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clusters2_new_userDict\n",
    "\n",
    "# key -----> number user cluster\n",
    "# value ----> books that are been rated by users inside number user cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clusters2_new_isbnDict\n",
    "\n",
    "# key -----> number book cluster\n",
    "# value ----> users that have rated books inside number book cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('clustering/file/clusters2_new_userDict.json', 'r') as fp:\n",
    "    \n",
    "    clusters_new_userDict = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('clustering/file/clusters2_new_isbnDict.json', 'r') as fp:\n",
    "    \n",
    "    clusters_new_isbnDict = json.load(fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "with open('clustering/file/clusters_dict_row.json', 'r') as fp:\n",
    "    \n",
    "    clusters_dict_row = json.load(fp)\n",
    "       \n",
    "with open('clustering/file/clusters_dict_col.json', 'r') as fp:\n",
    "    \n",
    "    clusters_dict_col = json.load(fp)\n",
    "    \n",
    "print(\"Ok\") \n",
    "\n",
    "with open('clustering/index_book_user_clusters/index_user_cluster.json', 'r') as fp:\n",
    "    \n",
    "    index_user_cluster = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('clustering/index_book_user_clusters/index_book_cluster.json', 'r') as fp:\n",
    "    \n",
    "    index_book_cluster = json.load(fp)\n",
    "    \n",
    "print(\"Ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for the moment we have only number_cluster(item or user) and all the element inside that cluster (users or items); for example inside clusters2_new_isbnDict[\"1] we have all the users that have rated books belonging at this cluster(the information of what books/users are inside what cluster is inside cluster_book_dict.json and cluster_users_dict.json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# but to compute the utility matrix I need to have a structure that contains number_cluster(item or user) and as values clusters(users or items) that have rated element inside number_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cluster_books\n",
    "\n",
    "# key -----> number book cluster\n",
    "# value -----> clusters of users that have rated number book cluster(the elements inside this cluster) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateClustersUsingClustersNewDicts(clusters_new_isbnDict, index_user_cluster):\n",
    "\n",
    "    clusters_books = {k:{} for k in clusters_new_isbnDict}\n",
    "\n",
    "    for c_i in clusters_new_isbnDict:\n",
    "\n",
    "        for user in clusters_new_isbnDict[c_i]:\n",
    "\n",
    "            try:\n",
    "                c_u = index_user_cluster[user]\n",
    "\n",
    "                if c_u not in clusters_books[c_i]:\n",
    "\n",
    "                    clusters_books[c_i][c_u] = []\n",
    "\n",
    "                if float(clusters_new_isbnDict[c_i][user]) != 0.0:\n",
    "\n",
    "                    clusters_books[c_i][c_u].append(float(clusters_new_isbnDict[c_i][user]))\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    for c_b in clusters_books:\n",
    "\n",
    "        users_cluster = list(clusters_books[c_b].keys())\n",
    "\n",
    "        for c_u in users_cluster:\n",
    "\n",
    "            if clusters_books[c_b][c_u] == []:\n",
    "\n",
    "                del clusters_books[c_b][c_u]\n",
    "            else:\n",
    "                clusters_books[c_b][c_u] = np.mean(clusters_books[c_b][c_u])\n",
    "                \n",
    "                \n",
    "    return clusters_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('clustering/CLUSTERS_ITEMS.json', 'r') as fp:\n",
    "    \n",
    "    CLUSTERS_ITEMS = json.load(fp)\n",
    "    \n",
    "    \n",
    "with open('clustering/CLUSTERS_USERS.json', 'r') as fp:\n",
    "    \n",
    "    CLUSTERS_USERS = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clusters_books = generateClustersUsingClustersNewDicts(clusters_new_isbnDict, index_user_cluster)\n",
    "\n",
    "#clusters_users = generateClustersUsingClustersNewDicts(clusters_new_userDict, index_book_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#u_clusters, R_clusters, utility_DataFrame_clusters = computeMatrices(CLUSTERS_USERS,CLUSTERS_ITEMS,\n",
    " #                                                                          CLUSTERS_USERS,CLUSTERS_ITEMS,\n",
    " #                                                                           clusters_dict_row,clusters_dict_col)\n",
    "\n",
    "#u, R, utility_DataFrame = computeMatrices(new_userDict,new_isbnDict,new_userDict,new_isbnDict,dict_row,dict_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I want to recommend some books to a certain user  using user/users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start considering all the books well rated by my choosen user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# item/items collaborative filtering  -----> a book to a certain user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the idea is that if number_user has given good ratings to books similar to number_book, probably number_user appreciates number_book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# take all the books rated (positive or negative) by number_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def booksRatedUser(new_isbnDict, new_userDict, user_number, score):\n",
    "    \n",
    "    '''\n",
    "    input:  new_userDict (Dict), user_number (int), score (int)\n",
    "    \n",
    "    action: select all books well rated by my user\n",
    "    \n",
    "    output: books_rated (list)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    books_rated = []\n",
    "    \n",
    "    for book in new_userDict[str(user_number)]:\n",
    "        \n",
    "        if int(new_userDict[str(user_number)][book]) > score:\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                new_isbnDict[book]\n",
    "                books_rated.append(book)\n",
    "                \n",
    "            except:\n",
    "                \n",
    "                continue\n",
    "            \n",
    "    return list(set(books_rated))\n",
    "\n",
    "\n",
    "def SimilarityBooks(utility_DataFrame, book_number, books_similar, measure = \"euclid\"):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    input: utility_DataFrame (DataFrame), book_number (int), books_similar (List)\n",
    "    \n",
    "    action: compute cosine similarity between book_number and all the books in books_similar\n",
    "    \n",
    "    output: new_similarity (List of tuples)\n",
    "    \n",
    "    '''\n",
    "\n",
    "    x = utility_DataFrame[str(book_number)]\n",
    "    x_length = norm(x)\n",
    "    \n",
    "    y = utility_DataFrame[books_similar]\n",
    "    y_length = norm(utility_DataFrame[books_similar],axis=0)\n",
    "\n",
    "    \n",
    "    num = (y.T.values*x.values).sum(axis=1)\n",
    "    \n",
    "    if measure == \"cos\":\n",
    "        den = x_length*y_length\n",
    "    else:\n",
    "        den = 1\n",
    "\n",
    "    similarity = num/den\n",
    "    similarity = np.nan_to_num(similarity)\n",
    "    \n",
    "    d = list(zip(list(books_similar),similarity))\n",
    "    new_similarity = sorted(d, key=lambda tup: tup[1], reverse=True)\n",
    "    \n",
    "    return new_similarity\n",
    "\n",
    "def itemItemsRecommendation(new_similarity, user_number, book_number, k, new_userDict):\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    input:  new_similarity(List of tuples), new_isbnDict(Dict), k(int)\n",
    "    \n",
    "    action: recommend item using the ratings of similar items\n",
    "    \n",
    "    output: recommendation (float)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    if len(new_similarity) < k:\n",
    "        \n",
    "        \n",
    "        recommendation = np.mean([u[1] for u in new_similarity])\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        for u in new_similarity[:k]:\n",
    "            \n",
    "            recommendation = np.mean([u[1] for u in new_similarity[:k]])\n",
    "        \n",
    "    \n",
    "    return recommendation\n",
    "\n",
    "def itemItemsScore(new_userDict, new_similarity, k, user_number):\n",
    "    \n",
    "    score = [int(new_userDict[str(user_number)][u[0]]) for u in new_similarity[:k]]\n",
    "    \n",
    "    if score == []:\n",
    "        \n",
    "        print(\"Not possible to perform recommendatios\")\n",
    "        return None\n",
    "    \n",
    "    return np.mean(score)\n",
    "\n",
    "def CollaborativeFilteringItemItems(utility_DataFrame, new_userDict, new_isbnDict, user_number, book_number, score_min, k):\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    generate the book_number rating for the user_number using similarity between number_book and book rated by number_user   \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    score = None\n",
    "    books_rated_user = booksRatedUser(new_isbnDict, new_userDict, user_number,score_min)\n",
    "    \n",
    "    \n",
    "    if books_rated_user == []:\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    new_similarity = SimilarityBooks(utility_DataFrame, book_number, books_rated_user)\n",
    "    \n",
    "    \n",
    "    if new_similarity == []:\n",
    "\n",
    "        return score\n",
    "    \n",
    "    recommendation = itemItemsRecommendation(new_similarity[1:], user_number, book_number, k, new_userDict)\n",
    "    \n",
    "    \n",
    "    if recommendation == 0.0:\n",
    "        \n",
    "        return score\n",
    "        \n",
    "        \n",
    "    score = itemItemsScore(new_userDict, new_similarity[1:], k, user_number)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mainItemItems_clustering(books_dataFrame, utility_DataFrame_cluster,R_cluster, new_userDict, new_isbnDict, d_user, d_isbn,\n",
    "                  index_user_cluster, index_book_cluster,\n",
    "                  score_min = 0, k = 3):\n",
    "    \n",
    "    \n",
    "    print(\"Please choose a user and/or an item\\n\")\n",
    "    print(\"user or random user: \\n\")\n",
    "    user_number = input()\n",
    "    if user_number == \"\":\n",
    "        user_number = None\n",
    "    print(\"item or random item: \\n\")\n",
    "    book_numbers = input()\n",
    "    if book_numbers == \"\":\n",
    "        book_numbers = None\n",
    "    \n",
    "    if user_number != None or book_numbers != None:\n",
    "        \n",
    "        if user_number == None:\n",
    "            \n",
    "            n = randint(0,len(new_userDict))\n",
    "            user_number = d_user[n]\n",
    "            \n",
    "        if book_numbers == None:\n",
    "            \n",
    "            m = randint(0,len(new_isbnDict))\n",
    "            book_numbers = d_isbn[m]\n",
    "        \n",
    "        for book_number in book_numbers.split():\n",
    "            score = None\n",
    "            \n",
    "            score = CollaborativeFilteringItemUsers(utility_DataFrame, new_userDict, new_isbnDict, user_number, book_number,\n",
    "                                                    score_min, k)\n",
    "            if score == None:\n",
    "\n",
    "                user_cluster, book_cluster = convert(user_number,book_number, index_user_cluster, index_book_cluster)\n",
    "\n",
    "                if R_cluster[book_cluster][user_cluster] == 1:\n",
    "\n",
    "                    score = utility_DataFrame_cluster[book_cluster][user_cluster]\n",
    "                    \n",
    "            if score == None:\n",
    "                    \n",
    "                    term1 = utility_DataFrame_cluster[book_cluster]\n",
    "                    r1 = R_cluster[book_cluster]\n",
    "                    term1 = term1[r1 ==1]\n",
    "                    \n",
    "                    term2 = utility_DataFrame_cluster.loc[user_cluster]\n",
    "                    r2 = R_cluster.loc[user_cluster]\n",
    "                    term2 = term2[r2==1]\n",
    "                    \n",
    "                    score = (np.mean(term1) + np.mean(term2))/2\n",
    "                    \n",
    "            if score == None:\n",
    "                print(\"Nothing to recommend\")\n",
    "                \n",
    "            else:    \n",
    "                try:\n",
    "                    print(\"\\nThe predicted rating (using item-based with clusterization) for book <\", \n",
    "                          books_dataFrame.loc[book_number][\"Book-Title\"], \" > given by user <\", user_number, \"> is\", np.round(score,3),\"\\n\")\n",
    "\n",
    "                except:\n",
    "                    print(book_number, user_number, score)\n",
    "                    \n",
    "            \n",
    "        \n",
    "    else:\n",
    "\n",
    "        score = None\n",
    "\n",
    "        while score == None:\n",
    "\n",
    "\n",
    "\n",
    "            n = randint(0,len(new_userDict))\n",
    "            m = randint(0,len(new_isbnDict))\n",
    "\n",
    "            user_number = d_user[n]\n",
    "            book_number = d_isbn[m]\n",
    "            \n",
    "            score = CollaborativeFilteringItemItems(utility_DataFrame, new_userDict, new_isbnDict, user_number, book_number, \n",
    "                                                    score_min, k)\n",
    "            \n",
    "            if score == None:\n",
    "            \n",
    "                user_cluster, book_cluster = convert(user_number,book_number, index_user_cluster, index_book_cluster)\n",
    "                \n",
    "                if R_cluster[book_cluster][user_cluster] == 1:\n",
    "                    \n",
    "                    score = utility_DataFrame_cluster[book_cluster][user_cluster]\n",
    "                    \n",
    "            if score == None:\n",
    "\n",
    "                    term1 = utility_DataFrame_cluster[book_cluster]\n",
    "                    r1 = R_cluster[book_cluster]\n",
    "                    term1 = term1[r1 ==1]\n",
    "\n",
    "                    term2 = utility_DataFrame_cluster.loc[user_cluster]\n",
    "                    r2 = R_cluster.loc[user_cluster]\n",
    "                    term2 = term2[r2==1]\n",
    "\n",
    "                    score = (np.mean(term1) + np.mean(term2))/2\n",
    "                    \n",
    "\n",
    "        try:\n",
    "            print(\"The predicted rating (using item-based with clusterization) for book <\", \n",
    "                  books_dataFrame.loc[book_number][\"Book-Title\"], \" > given by user <\", user_number, \"> is\", np.round(score,3))\n",
    "\n",
    "        except:\n",
    "            print(book_number, user_number, score)\n",
    "        \n",
    "    #return book_number, user_number, score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# item/users collaborative filtering  -----> a book to a certain user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the idea is that if number_user is (really) similar to a user that has given a good rating to number_book, probably also number_user appreciates number_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ATTENTION!!!  different respect to usersHaveRatedBook(s)\n",
    "\n",
    "def usersHaveRatedBook(new_isbnDict, new_userDict, book_number, score):\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    input:  new_isbnDict (Dict), new_userDict (Dict), book_number (int), score (int)\n",
    "    \n",
    "    action: select all users that have given a good rating to book_number\n",
    "    \n",
    "    output: users_rated (list)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    users_rated = []\n",
    "    \n",
    "    for user in new_isbnDict[str(book_number)]:\n",
    "        \n",
    "        if int(new_isbnDict[str(book_number)][user]) > score:\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                new_userDict[user]\n",
    "                users_rated.append(user)\n",
    "                \n",
    "            except:\n",
    "                \n",
    "                continue\n",
    "            \n",
    "    return list(set(users_rated))\n",
    "\n",
    "\n",
    "#users_rated_book = usersHaveRatedBook(new_isbnDict, new_userDict, book_number, 5)\n",
    "\n",
    "def SimilarityUsers(utility_DataFrame, user_number, users_similar, measure = \"euclid\"):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    input: utility_DataFrame (DataFrame), user_number (int), user_similar (List)\n",
    "    \n",
    "    action: compute cosine similarity between user_number and all the user in users_similar\n",
    "    \n",
    "    output: new_similarity (List of tuples)\n",
    "    \n",
    "    '''\n",
    "\n",
    "    x = utility_DataFrame.loc[str(user_number)]\n",
    "    x_length = norm(x)\n",
    "    \n",
    "    y = utility_DataFrame.loc[users_similar]\n",
    "    y_length = norm(utility_DataFrame.loc[users_similar],axis=1)\n",
    "\n",
    "    \n",
    "    num = (y.values*x.values).sum(axis=1)\n",
    "    \n",
    "    if measure == \"cos\":\n",
    "        den = x_length*y_length\n",
    "    else:\n",
    "        den = 1\n",
    "\n",
    "    similarity = num/den\n",
    "    similarity = np.nan_to_num(similarity)\n",
    "    \n",
    "    d = list(zip(list(users_similar),similarity))\n",
    "    new_similarity = sorted(d, key=lambda tup: tup[1], reverse=True)\n",
    "    \n",
    "    \n",
    "    return new_similarity\n",
    "\n",
    "def ItemUsersRecommendation(new_similarity, new_userDict, k):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    input:  new_similarity(List of tuples), new_userDict(Dict), score(int), k(int)\n",
    "    \n",
    "    action: recommend items using the ratings of similar users\n",
    "    \n",
    "    output: recommendation (Dict), books (Dict)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if new_similarity == []:\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    if len(new_similarity) > k:\n",
    "    \n",
    "        recommendation = np.mean([u[1] for u in new_similarity[:k]]) \n",
    "    \n",
    "    else:\n",
    "        \n",
    "        recommendation = np.mean([u[1] for u in new_similarity]) \n",
    "        \n",
    "    return recommendation\n",
    "\n",
    "def itemUsersScore(new_similarity,new_isbnDict, book_number, k):\n",
    "    \n",
    "    if new_similarity == []:\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    if len(new_similarity) > k:\n",
    "        \n",
    "        score = [int(new_isbnDict[str(book_number)][u[0]]) for u in new_similarity[:k] if u[1] !=0.0]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        score = [int(new_isbnDict[str(book_number)][u[0]]) for u in new_similarity if u[1] !=0.0]\n",
    "    \n",
    "    return np.mean(score)\n",
    "\n",
    "def CollaborativeFilteringItemUsers(utility_DataFrame, new_userDict, new_isbnDict, user_number, book_number, score_min = 0, k = 3):\n",
    "    \n",
    "    score = None\n",
    "    users_rated_book = usersHaveRatedBook(new_isbnDict, new_userDict, book_number, score_min)\n",
    "    \n",
    "    \n",
    "    if users_rated_book == []:\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    \n",
    "    new_similarity = SimilarityUsers(utility_DataFrame, user_number, users_rated_book)\n",
    "    \n",
    "    \n",
    "    if new_similarity == []:\n",
    "\n",
    "        return score\n",
    "    \n",
    "    recommendation = ItemUsersRecommendation(new_similarity, new_userDict, k)\n",
    "    \n",
    "        \n",
    "    if recommendation == 0.0:\n",
    "        \n",
    "        return score\n",
    "        \n",
    "    score = itemUsersScore(new_similarity,new_isbnDict, book_number, k)\n",
    "    \n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mainItemUsers_clustering(books_dataFrame, utility_DataFrame_cluster, R_cluster, new_userDict, new_isbnDict, d_user, d_isbn,\n",
    "                  index_user_cluster, index_book_cluster,\n",
    "                  score_min = 0, k = 3):\n",
    "    \n",
    "    \n",
    "    print(\"Please choose a user and/or an item\\n\")\n",
    "    print(\"user or random user: \\n\")\n",
    "    user_number = input()\n",
    "    if user_number == \"\":\n",
    "        user_number = None\n",
    "    print(\"item or random item: \\n\")\n",
    "    book_numbers = input()\n",
    "    if book_numbers == \"\":\n",
    "        book_numbers = None\n",
    "    \n",
    "    if user_number != None or book_numbers != None:\n",
    "        \n",
    "        if user_number == None:\n",
    "            \n",
    "            n = randint(0,len(new_userDict))\n",
    "            user_number = d_user[n]\n",
    "            \n",
    "        if book_numbers == None:\n",
    "            \n",
    "            m = randint(0,len(new_isbnDict))\n",
    "            book_numbers = d_isbn[m]\n",
    "        \n",
    "        for book_number in book_numbers.split():\n",
    "            \n",
    "            score = None\n",
    "            \n",
    "            score = CollaborativeFilteringItemUsers(utility_DataFrame, new_userDict, new_isbnDict, user_number, book_number,\n",
    "                                                    score_min, k)\n",
    "            if score == None:\n",
    "\n",
    "                user_cluster, book_cluster = convert(user_number,book_number, index_user_cluster, index_book_cluster)\n",
    "\n",
    "                if R_cluster[book_cluster][user_cluster] == 1:\n",
    "\n",
    "                        score = utility_DataFrame_cluster[book_cluster][user_cluster]\n",
    "                        \n",
    "                if score == None:\n",
    "\n",
    "                    term1 = utility_DataFrame_cluster[book_cluster]\n",
    "                    r1 = R_cluster[book_cluster]\n",
    "                    term1 = term1[r1 ==1]\n",
    "\n",
    "                    term2 = utility_DataFrame_cluster.loc[user_cluster]\n",
    "                    r2 = R_cluster.loc[user_cluster]\n",
    "                    term2 = term2[r2==1]\n",
    "\n",
    "                    score = (np.mean(term1) + np.mean(term2))/2\n",
    "                    \n",
    "            if score == None:\n",
    "                print(\"Nothing to recommend\")\n",
    "            else:\n",
    "                try:\n",
    "                    print(\"\\nThe predicted rating (using user-based with clusterization) for book <\", \n",
    "                      books_dataFrame.loc[str(book_number)][\"Book-Title\"], \"> given by user <\", user_number, \"> is\", np.round(score,3), \"\\n\")\n",
    "\n",
    "                except:\n",
    "                    print(book_number, user_number, score)\n",
    "           \n",
    "                \n",
    "    else:\n",
    "            \n",
    "        score = None\n",
    "\n",
    "        while score == None:\n",
    "\n",
    "\n",
    "            n = randint(0,len(new_userDict))\n",
    "            m = randint(0,len(new_isbnDict))\n",
    "\n",
    "            user_number = d_user[n]\n",
    "            book_number = d_isbn[m]\n",
    "            \n",
    "\n",
    "            score = CollaborativeFilteringItemUsers(utility_DataFrame, new_userDict, new_isbnDict, user_number, book_number,\n",
    "                                                    score_min,k)\n",
    "            if score == None:\n",
    "            \n",
    "                user_cluster, book_cluster = convert(user_number,book_number, index_user_cluster, index_book_cluster)\n",
    "                \n",
    "                if R_cluster[book_cluster][user_cluster] == 1:\n",
    "                    \n",
    "                    score = utility_DataFrame_cluster[book_cluster][user_cluster]\n",
    "                    \n",
    "                if score == None:\n",
    "\n",
    "                    term1 = utility_DataFrame_cluster[book_cluster]\n",
    "                    r1 = R_cluster[book_cluster]\n",
    "                    term1 = term1[r1 ==1]\n",
    "\n",
    "                    term2 = utility_DataFrame_cluster.loc[user_cluster]\n",
    "                    r2 = R_cluster.loc[user_cluster]\n",
    "                    term2 = term2[r2==1]\n",
    "\n",
    "                    score = (np.mean(term1) + np.mean(term2))/2\n",
    "                    \n",
    "        try:\n",
    "\n",
    "            print(\"The predicted rating (using user-based with clusterization) for book <\", \n",
    "              books_dataFrame.loc[str(book_number)][\"Book-Title\"], \"> given by user <\", user_number, \"> is\", np.round(score,3))\n",
    "\n",
    "        except:\n",
    "\n",
    "            print(book_number, user_number, score)\n",
    "\n",
    "    \n",
    "    \n",
    "    #return book_number, user_number, score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mainClustering(books_dataFrame, utility_DataFrame_cluster,R_cluster, new_userDict, new_isbnDict, d_user, d_isbn,\n",
    "                  index_user_cluster, index_book_cluster):\n",
    "    \n",
    "    \n",
    "    print(\"Please choose a user and/or an item\\n\")\n",
    "    print(\"user or random user: \\n\")\n",
    "    user_number = input()\n",
    "    if user_number == \"\":\n",
    "        user_number = None\n",
    "    print(\"item or random item: \\n\")\n",
    "    book_numbers = input()\n",
    "    if book_numbers == \"\":\n",
    "        book_numbers = None\n",
    "    \n",
    "    if user_number != None or book_numbers != None:\n",
    "        \n",
    "        if user_number == None:\n",
    "            \n",
    "            n = randint(0,len(new_userDict))\n",
    "            user_number = d_user[n]\n",
    "            \n",
    "        if book_numbers == None:\n",
    "            \n",
    "            m = randint(0,len(new_isbnDict))\n",
    "            book_numbers = d_isbn[m]\n",
    "        \n",
    "        for book_number in book_numbers.split():\n",
    "            \n",
    "            try:\n",
    "                score = None\n",
    "                user_cluster, book_cluster = convert(user_number,book_number, index_user_cluster, index_book_cluster)\n",
    "                if R_cluster[book_cluster][user_cluster] == 1:\n",
    "                        score = utility_DataFrame_cluster[book_cluster][user_cluster]\n",
    "                        \n",
    "                if score == None:\n",
    "                    \n",
    "                    term1 = utility_DataFrame_cluster[book_cluster]\n",
    "                    r1 = R_cluster[book_cluster]\n",
    "                    term1 = term1[r1 ==1]\n",
    "                    \n",
    "                    term2 = utility_DataFrame_cluster.loc[user_cluster]\n",
    "                    r2 = R_cluster.loc[user_cluster]\n",
    "                    term2 = term2[r2==1]\n",
    "                    \n",
    "                    score = (np.mean(term1) + np.mean(term2))/2\n",
    "                        \n",
    "                if score == None:\n",
    "                    print(\"Nothing to recommend\")\n",
    "                else:\n",
    "                    try:\n",
    "                        print(\"\\nThe predicted rating (using user-based with clusterization) for book <\", \n",
    "                          books_dataFrame.loc[str(book_number)][\"Book-Title\"], \"> given by user <\", user_number, \"> is\", \n",
    "                              np.round(score,3),\"\\n\")\n",
    "                    except:\n",
    "                        print(book_number, user_number, score)\n",
    "                \n",
    "            except:\n",
    "                continue\n",
    "                    \n",
    "    else:\n",
    "            \n",
    "        score = None\n",
    "\n",
    "        while score == None:\n",
    "\n",
    "\n",
    "            n = randint(0,len(new_userDict))\n",
    "            m = randint(0,len(new_isbnDict))\n",
    "\n",
    "            user_number = d_user[n]\n",
    "            book_number = d_isbn[m]\n",
    "            \n",
    "            try:\n",
    "                user_cluster, book_cluster = convert(user_number,book_number, index_user_cluster, index_book_cluster)\n",
    "\n",
    "                if R_cluster[book_cluster][user_cluster] == 1:\n",
    "\n",
    "                    score = utility_DataFrame_cluster[book_cluster][user_cluster]\n",
    "                    \n",
    "                if score == None:\n",
    "\n",
    "                    term1 = utility_DataFrame_cluster[book_cluster]\n",
    "                    r1 = R_cluster[book_cluster]\n",
    "                    term1 = term1[r1 ==1]\n",
    "\n",
    "                    term2 = utility_DataFrame_cluster.loc[user_cluster]\n",
    "                    r2 = R_cluster.loc[user_cluster]\n",
    "                    term2 = term2[r2==1]\n",
    "\n",
    "                    score = (np.mean(term1) + np.mean(term2))/2\n",
    "                    \n",
    "            except:\n",
    "                continue\n",
    "        try:\n",
    "\n",
    "            print(\"The predicted rating (using user-based with clusterization) for book <\", \n",
    "              books_dataFrame.loc[str(book_number)][\"Book-Title\"], \"> given by user <\", user_number, \"> is\", np.round(score,3))\n",
    "\n",
    "        except:\n",
    "\n",
    "            print(book_number, user_number, score)\n",
    "\n",
    "    \n",
    "    \n",
    "    #return book_number, user_number, score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mainCollaborativeFiltering_CLUSTERING(books_dataFrame, utility_DataFrame_cluster,R_cluster, new_userDict, new_isbnDict,\n",
    "                                          index_user_cluster, index_book_cluster,\n",
    "                                          d_user = None, d_isbn = None, score_min = 0, k = 3):\n",
    "    \n",
    "    n = -1\n",
    "    \n",
    "    d_user = sorted(new_userDict.keys())\n",
    "    d_isbn = sorted(new_isbnDict.keys())\n",
    "    \n",
    "    while n not in [1,2,3]:\n",
    "    \n",
    "        print(\"What method do you want to try?\\n\")\n",
    "\n",
    "        print(\"1 CollaborativeFilteringItemItems using clustering\")\n",
    "        print(\"2 CollaborativeFilteringItemUsers using clustering\")\n",
    "        print(\"3 CollaborativeFiltering clustering approach\")\n",
    "        \n",
    "        try:\n",
    "            n = int(input())\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    if n == 1:\n",
    "    \n",
    "        mainItemItems_clustering(books_dataFrame, utility_DataFrame_cluster,R_cluster,new_userDict, new_isbnDict, d_user, d_isbn,\n",
    "                      index_user_cluster, index_book_cluster,\n",
    "                      score_min, k)\n",
    "    elif n == 2:\n",
    "    \n",
    "        mainItemUsers_clustering(books_dataFrame, utility_DataFrame_cluster,R_cluster,new_userDict, new_isbnDict, d_user, d_isbn,\n",
    "                      index_user_cluster, index_book_cluster,\n",
    "                      score_min, k)\n",
    "        \n",
    "    elif n ==3:\n",
    "        \n",
    "        mainClustering(books_dataFrame, utility_DataFrame_cluster,R_cluster, new_userDict, new_isbnDict, d_user, d_isbn,\n",
    "                  index_user_cluster, index_book_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u_cluster, R_cluster, utility_DataFrame_cluster = computeMatrices(CLUSTERS_USERS,CLUSTERS_ITEMS,\n",
    "                                                                           CLUSTERS_USERS,CLUSTERS_ITEMS,\n",
    "                                                                            clusters_dict_row,clusters_dict_col)\n",
    "\n",
    "\n",
    "u, R, utility_DataFrame = computeMatrices(new_userDict,new_isbnDict,new_userDict,new_isbnDict,dict_row,dict_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What method do you want to try?\n",
      "\n",
      "1 CollaborativeFilteringItemItems using clustering\n",
      "2 CollaborativeFilteringItemUsers using clustering\n",
      "3 CollaborativeFiltering clustering approach\n",
      "1\n",
      "Please choose a user and/or an item\n",
      "\n",
      "user or random user: \n",
      "\n",
      "\n",
      "item or random item: \n",
      "\n",
      "\n",
      "The predicted rating (using item-based with clusterization) for book < Per Anhalter durch die Galaxis.  > given by user < 231612 > is 8.0\n",
      "\n",
      "Another try?\n",
      "\n",
      "y\n",
      "n\n",
      "y\n",
      "What method do you want to try?\n",
      "\n",
      "1 CollaborativeFilteringItemItems using clustering\n",
      "2 CollaborativeFilteringItemUsers using clustering\n",
      "3 CollaborativeFiltering clustering approach\n",
      "\n",
      "What method do you want to try?\n",
      "\n",
      "1 CollaborativeFilteringItemItems using clustering\n",
      "2 CollaborativeFilteringItemUsers using clustering\n",
      "3 CollaborativeFiltering clustering approach\n",
      "3\n",
      "Please choose a user and/or an item\n",
      "\n",
      "user or random user: \n",
      "\n",
      "\n",
      "item or random item: \n",
      "\n",
      "\n",
      "The predicted rating (using user-based with clusterization) for book < The Lion, the Witch and the Wardrobe (rpkg) (Narnia) > given by user < 3189 > is 7.273\n",
      "\n",
      "Another try?\n",
      "\n",
      "y\n",
      "n\n",
      "y\n",
      "What method do you want to try?\n",
      "\n",
      "1 CollaborativeFilteringItemItems using clustering\n",
      "2 CollaborativeFilteringItemUsers using clustering\n",
      "3 CollaborativeFiltering clustering approach\n",
      "2\n",
      "Please choose a user and/or an item\n",
      "\n",
      "user or random user: \n",
      "\n",
      "\n",
      "item or random item: \n",
      "\n",
      "\n",
      "The predicted rating (using user-based with clusterization) for book < L' Etranger > given by user < 250832 > is 6.866\n",
      "\n",
      "Another try?\n",
      "\n",
      "y\n",
      "n\n",
      "y\n",
      "What method do you want to try?\n",
      "\n",
      "1 CollaborativeFilteringItemItems using clustering\n",
      "2 CollaborativeFilteringItemUsers using clustering\n",
      "3 CollaborativeFiltering clustering approach\n",
      "1\n",
      "Please choose a user and/or an item\n",
      "\n",
      "user or random user: \n",
      "\n",
      "120908\n",
      "item or random item: \n",
      "\n",
      "\n",
      "\n",
      "The predicted rating (using item-based with clusterization) for book < E=mc2: A Biography of the World's Most Famous Equation  > given by user < 120908 > is 9.0 \n",
      "\n",
      "\n",
      "Another try?\n",
      "\n",
      "y\n",
      "n\n",
      "n\n",
      "Bye\n"
     ]
    }
   ],
   "source": [
    "r = -1\n",
    "\n",
    "mainCollaborativeFiltering_CLUSTERING(books_dataFrame, utility_DataFrame_cluster,R_cluster, new_userDict, new_isbnDict,\n",
    "                                          index_user_cluster, index_book_cluster)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    print(\"\\nAnother try?\\n\")\n",
    "    print(\"y\")\n",
    "    print(\"n\")\n",
    "    \n",
    "    r = input()\n",
    "    \n",
    "    if r == \"y\":\n",
    "        mainCollaborativeFiltering_CLUSTERING(books_dataFrame, utility_DataFrame_cluster,R_cluster, new_userDict, new_isbnDict,\n",
    "                                          index_user_cluster, index_book_cluster)\n",
    "        \n",
    "    elif r == \"n\":\n",
    "        \n",
    "        print(\"Bye\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_userDict[\"120908\"]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
